{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Maximum, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from Ensemble_Classifiers import Ensemble_Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "global seed\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalGAN():\n",
    "    def __init__(self, blackbox, X, Y, threshold):\n",
    "        self.apifeature_dims = 135\n",
    "        self.z_dims = 100\n",
    "        # self.generator_layers = [self.apifeature_dims+self.z_dims, 32, 64, 64, self.apifeature_dims]\n",
    "        self.generator_layers = [self.apifeature_dims+self.z_dims, 64, 64, 64, 128, self.apifeature_dims]\n",
    "        # self.generator_layers = [self.apifeature_dims+self.z_dims, 64, 128, self.apifeature_dims]\n",
    "        \n",
    "        # self.substitute_detector_layers = [self.apifeature_dims, 64, 64, 1]\n",
    "        self.substitute_detector_layers = [self.apifeature_dims, 128, 128, 128, 1]\n",
    "        # self.substitute_detector_layers = [self.apifeature_dims, 128, 1]\n",
    "        \n",
    "        self.blackbox = blackbox       \n",
    "        optimizer = adam_v2.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # Build and Train blackbox_detector\n",
    "        self.blackbox_detector = self.build_blackbox_detector()\n",
    "\n",
    "        # Build and compile the substitute_detector\n",
    "        self.substitute_detector = self.build_substitute_detector()\n",
    "        self.substitute_detector.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes malware and noise as input and generates adversarial malware examples\n",
    "        example = Input(shape=(self.apifeature_dims,))\n",
    "        noise = Input(shape=(self.z_dims,))\n",
    "        input = [example, noise]\n",
    "        malware_examples = self.generator(input)\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.substitute_detector(malware_examples)\n",
    "\n",
    "        # The combined model  (stacked generator and substitute_detector)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(input, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.substitute_detector.trainable = False\n",
    "    \n",
    "    def load_data(self):\n",
    "        x_ran, x_ben,y_ran, y_ben = self.X[:self.threshold], self.X[self.threshold:], self.Y[:self.threshold], self.Y[self.threshold:]\n",
    "\n",
    "        return (x_ran, y_ran), (x_ben, y_ben)\n",
    "    \n",
    "    def build_blackbox_detector(self):\n",
    "        if self.blackbox in ['SVM']:\n",
    "            blackbox_detector = SVC(kernel = 'linear')\n",
    "        \n",
    "        elif self.blackbox in ['GB']:\n",
    "            blackbox_detector = GradientBoostingClassifier(random_state=seed)\n",
    "        \n",
    "        elif self.blackbox in ['SGD']:\n",
    "            blackbox_detector = SGDClassifier(random_state=seed)  \n",
    "\n",
    "        elif self.blackbox in ['DT']:\n",
    "            blackbox_detector = DecisionTreeClassifier(random_state=seed)\n",
    "        \n",
    "        elif self.blackbox in ['Ensem']:\n",
    "            blackbox_detector = Ensemble_Classifier()\n",
    "\n",
    "        return blackbox_detector\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        example = Input(shape=(self.apifeature_dims,))\n",
    "        noise = Input(shape=(self.z_dims,))\n",
    "        x = Concatenate(axis=1)([example, noise])\n",
    "        for dim in self.generator_layers[1:]:\n",
    "            x = Dense(dim)(x)\n",
    "        x = Activation(activation='tanh')(x)\n",
    "        x = Maximum()([example, x])\n",
    "        generator = Model([example, noise], x, name='generator')\n",
    "        generator.summary()\n",
    "        return generator\n",
    "\n",
    "    def build_substitute_detector(self):\n",
    "\n",
    "        input = Input(shape=(self.substitute_detector_layers[0],))\n",
    "        x = input\n",
    "        for dim in self.substitute_detector_layers[1:]:\n",
    "            x = Dense(dim)(x)\n",
    "        x = Activation(activation='sigmoid')(x)\n",
    "        substitute_detector = Model(input, x, name='substitute_detector')\n",
    "        substitute_detector.summary()\n",
    "        return substitute_detector\n",
    "\n",
    "\n",
    "    \n",
    "    def train(self, epochs, batch_size=32):\n",
    "\n",
    "        # Load and Split the dataset\n",
    "        (xmal, ymal), (xben, yben) = self.load_data()\n",
    "        xtrain_mal, xtest_mal, ytrain_mal, ytest_mal = train_test_split(xmal, ymal, test_size=0.50)\n",
    "        xtrain_ben, xtest_ben, ytrain_ben, ytest_ben = train_test_split(xben, yben, test_size=0.50)\n",
    "\n",
    "        bl_xtrain_mal, bl_ytrain_mal, bl_xtrain_ben, bl_ytrain_ben = xtrain_mal, ytrain_mal, xtrain_ben, ytrain_ben\n",
    "\n",
    "        \n",
    "        self.blackbox_detector.fit(np.concatenate([xmal, xben]), np.concatenate([ymal, yben]))\n",
    "\n",
    "        ytrain_ben_blackbox = self.blackbox_detector.predict(bl_xtrain_ben)\n",
    "        \n",
    "        Original_Train_TPR = self.blackbox_detector.score(bl_xtrain_mal, bl_ytrain_mal)\n",
    "        \n",
    "        Original_Test_TPR = self.blackbox_detector.score(xtest_mal, ytest_mal)\n",
    "        Train_TPR, Test_TPR = [Original_Train_TPR], [Original_Test_TPR]\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for step in range(xtrain_mal.shape[0] // batch_size):\n",
    "                # ---------------------\n",
    "                #  Train substitute_detector\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of malware examples\n",
    "                idx_mal = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n",
    "  \n",
    "                xmal_batch = xtrain_mal[idx_mal]\n",
    "                \n",
    "                noise = np.random.normal(0, 1, (batch_size, self.z_dims))\n",
    "                \n",
    "                idx_ben = np.random.randint(0, xmal_batch.shape[0], batch_size)\n",
    "                \n",
    "                xben_batch = xtrain_ben[idx_ben]\n",
    "                yben_batch = ytrain_ben_blackbox[idx_ben]\n",
    "\n",
    "                # Generate a batch of new malware examples\n",
    "                gen_examples = self.generator.predict([xmal_batch, noise])\n",
    "                ymal_batch = self.blackbox_detector.predict(np.ones(gen_examples.shape)*(gen_examples > 0.5))\n",
    "\n",
    "                # Train the substitute_detector\n",
    "\n",
    "                d_loss_real = self.substitute_detector.train_on_batch(gen_examples, ymal_batch)\n",
    "                d_loss_fake = self.substitute_detector.train_on_batch(xben_batch, yben_batch)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                idx = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n",
    "                xmal_batch = xtrain_mal[idx]\n",
    "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
    "\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([xmal_batch, noise], np.zeros((batch_size, 1)))\n",
    "\n",
    "            # Compute Train TPR\n",
    "            noise = np.random.uniform(0, 1, (xtrain_mal.shape[0], self.z_dims))\n",
    "            gen_examples = self.generator.predict([xtrain_mal, noise])\n",
    "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytrain_mal)\n",
    "            Train_TPR.append(TPR)\n",
    "\n",
    "            # Compute Test TPR\n",
    "            noise = np.random.uniform(0, 1, (xtest_mal.shape[0], self.z_dims))\n",
    "            gen_examples = self.generator.predict([xtest_mal, noise])\n",
    "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytest_mal)\n",
    "            Test_TPR.append(TPR)\n",
    "\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            if int(epoch) == int(epochs-1):\n",
    "                return  d_loss[0], 100*d_loss[1], g_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dict to save the D loss, acc and G loss for different classifiers\n",
    "D_loss_dict, Acc_dict, G_loss_dict = {}, {}, {}\n",
    "# get the data from Feature-Selector\n",
    "X = np.loadtxt('../dataset/matrix/X_fs.csv')\n",
    "Y = np.loadtxt('../dataset/matrix/Y_str.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321, 135)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] \n",
      "Training the model with SVM classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_151 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " dense_230 (Dense)           (None, 128)               17408     \n",
      "                                                                 \n",
      " dense_231 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_232 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_233 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_152 (InputLayer)         [(None, 135)]        0           []                               \n",
      "                                                                                                  \n",
      " input_153 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_30 (Concatenate)   (None, 235)          0           ['input_152[0][0]',              \n",
      "                                                                  'input_153[0][0]']              \n",
      "                                                                                                  \n",
      " dense_234 (Dense)              (None, 64)           15104       ['concatenate_30[0][0]']         \n",
      "                                                                                                  \n",
      " dense_235 (Dense)              (None, 64)           4160        ['dense_234[0][0]']              \n",
      "                                                                                                  \n",
      " dense_236 (Dense)              (None, 64)           4160        ['dense_235[0][0]']              \n",
      "                                                                                                  \n",
      " dense_237 (Dense)              (None, 128)          8320        ['dense_236[0][0]']              \n",
      "                                                                                                  \n",
      " dense_238 (Dense)              (None, 135)          17415       ['dense_237[0][0]']              \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 135)          0           ['dense_238[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_30 (Maximum)           (None, 135)          0           ['input_152[0][0]',              \n",
      "                                                                  'activation_61[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,159\n",
      "Trainable params: 49,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.739075, acc.: 45.31%] [G loss: 0.577934]\n",
      "1 [D loss: 0.718814, acc.: 45.31%] [G loss: 0.340810]\n",
      "2 [D loss: 0.607727, acc.: 62.50%] [G loss: 0.200938]\n",
      "3 [D loss: 0.803575, acc.: 48.44%] [G loss: 0.203315]\n",
      "4 [D loss: 0.659585, acc.: 59.38%] [G loss: 0.132210]\n",
      "5 [D loss: 0.593822, acc.: 60.94%] [G loss: 0.159712]\n",
      "6 [D loss: 0.531104, acc.: 68.75%] [G loss: 0.119516]\n",
      "7 [D loss: 0.507755, acc.: 68.75%] [G loss: 0.105147]\n",
      "8 [D loss: 0.536467, acc.: 60.94%] [G loss: 0.077931]\n",
      "9 [D loss: 0.509232, acc.: 75.00%] [G loss: 0.080387]\n",
      "10 [D loss: 0.499107, acc.: 67.19%] [G loss: 0.078012]\n",
      "11 [D loss: 0.479275, acc.: 78.12%] [G loss: 0.095767]\n",
      "12 [D loss: 0.434428, acc.: 78.12%] [G loss: 0.068320]\n",
      "13 [D loss: 0.408745, acc.: 82.81%] [G loss: 0.017934]\n",
      "14 [D loss: 0.364640, acc.: 79.69%] [G loss: 0.033349]\n",
      "15 [D loss: 0.373277, acc.: 82.81%] [G loss: 0.055725]\n",
      "16 [D loss: 0.463941, acc.: 76.56%] [G loss: 0.052778]\n",
      "17 [D loss: 0.303385, acc.: 81.25%] [G loss: 0.034562]\n",
      "18 [D loss: 0.308279, acc.: 82.81%] [G loss: 0.057437]\n",
      "19 [D loss: 0.269317, acc.: 89.06%] [G loss: 0.019595]\n",
      "20 [D loss: 0.268689, acc.: 89.06%] [G loss: 0.027109]\n",
      "21 [D loss: 0.314185, acc.: 93.75%] [G loss: 0.011741]\n",
      "22 [D loss: 0.319928, acc.: 85.94%] [G loss: 0.013135]\n",
      "23 [D loss: 0.204053, acc.: 92.19%] [G loss: 0.010202]\n",
      "24 [D loss: 0.264470, acc.: 89.06%] [G loss: 0.014862]\n",
      "25 [D loss: 0.280603, acc.: 93.75%] [G loss: 0.006426]\n",
      "26 [D loss: 0.281252, acc.: 89.06%] [G loss: 0.006070]\n",
      "27 [D loss: 0.282802, acc.: 90.62%] [G loss: 0.005017]\n",
      "28 [D loss: 0.249572, acc.: 95.31%] [G loss: 0.002672]\n",
      "29 [D loss: 0.125026, acc.: 98.44%] [G loss: 0.005628]\n",
      "30 [D loss: 0.198835, acc.: 95.31%] [G loss: 0.004818]\n",
      "31 [D loss: 0.364662, acc.: 89.06%] [G loss: 0.016090]\n",
      "32 [D loss: 0.225320, acc.: 95.31%] [G loss: 0.006555]\n",
      "33 [D loss: 0.113434, acc.: 95.31%] [G loss: 0.001876]\n",
      "34 [D loss: 0.209252, acc.: 93.75%] [G loss: 0.002578]\n",
      "35 [D loss: 0.392777, acc.: 89.06%] [G loss: 0.006887]\n",
      "36 [D loss: 0.132664, acc.: 95.31%] [G loss: 0.001580]\n",
      "37 [D loss: 0.191472, acc.: 93.75%] [G loss: 0.002475]\n",
      "38 [D loss: 0.267189, acc.: 89.06%] [G loss: 0.002444]\n",
      "39 [D loss: 0.245802, acc.: 95.31%] [G loss: 0.002470]\n",
      "40 [D loss: 0.199269, acc.: 90.62%] [G loss: 0.002529]\n",
      "41 [D loss: 0.239283, acc.: 90.62%] [G loss: 0.002830]\n",
      "42 [D loss: 0.188054, acc.: 95.31%] [G loss: 0.002290]\n",
      "43 [D loss: 0.129470, acc.: 96.88%] [G loss: 0.001114]\n",
      "44 [D loss: 0.272415, acc.: 89.06%] [G loss: 0.001349]\n",
      "45 [D loss: 0.333104, acc.: 87.50%] [G loss: 0.004971]\n",
      "46 [D loss: 0.138667, acc.: 95.31%] [G loss: 0.002469]\n",
      "47 [D loss: 0.186099, acc.: 93.75%] [G loss: 0.002807]\n",
      "48 [D loss: 0.162553, acc.: 93.75%] [G loss: 0.001795]\n",
      "49 [D loss: 0.172025, acc.: 93.75%] [G loss: 0.000989]\n",
      "[+] \n",
      "Training the model with SGD classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_156 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " dense_239 (Dense)           (None, 128)               17408     \n",
      "                                                                 \n",
      " dense_240 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_241 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_242 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_62 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_157 (InputLayer)         [(None, 135)]        0           []                               \n",
      "                                                                                                  \n",
      " input_158 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_31 (Concatenate)   (None, 235)          0           ['input_157[0][0]',              \n",
      "                                                                  'input_158[0][0]']              \n",
      "                                                                                                  \n",
      " dense_243 (Dense)              (None, 64)           15104       ['concatenate_31[0][0]']         \n",
      "                                                                                                  \n",
      " dense_244 (Dense)              (None, 64)           4160        ['dense_243[0][0]']              \n",
      "                                                                                                  \n",
      " dense_245 (Dense)              (None, 64)           4160        ['dense_244[0][0]']              \n",
      "                                                                                                  \n",
      " dense_246 (Dense)              (None, 128)          8320        ['dense_245[0][0]']              \n",
      "                                                                                                  \n",
      " dense_247 (Dense)              (None, 135)          17415       ['dense_246[0][0]']              \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 135)          0           ['dense_247[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_31 (Maximum)           (None, 135)          0           ['input_157[0][0]',              \n",
      "                                                                  'activation_63[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,159\n",
      "Trainable params: 49,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.753358, acc.: 48.44%] [G loss: 0.678516]\n",
      "1 [D loss: 0.779409, acc.: 59.38%] [G loss: 0.402512]\n",
      "2 [D loss: 0.632404, acc.: 70.31%] [G loss: 0.286220]\n",
      "3 [D loss: 0.552555, acc.: 68.75%] [G loss: 0.224177]\n",
      "4 [D loss: 0.593721, acc.: 64.06%] [G loss: 0.191887]\n",
      "5 [D loss: 0.450548, acc.: 81.25%] [G loss: 0.125884]\n",
      "6 [D loss: 0.565493, acc.: 67.19%] [G loss: 0.111996]\n",
      "7 [D loss: 0.449411, acc.: 81.25%] [G loss: 0.100956]\n",
      "8 [D loss: 0.436232, acc.: 79.69%] [G loss: 0.074162]\n",
      "9 [D loss: 0.526726, acc.: 71.88%] [G loss: 0.058089]\n",
      "10 [D loss: 0.451235, acc.: 78.12%] [G loss: 0.087045]\n",
      "11 [D loss: 0.369455, acc.: 82.81%] [G loss: 0.043041]\n",
      "12 [D loss: 0.442241, acc.: 73.44%] [G loss: 0.035658]\n",
      "13 [D loss: 0.396816, acc.: 82.81%] [G loss: 0.045415]\n",
      "14 [D loss: 0.323018, acc.: 84.38%] [G loss: 0.025812]\n",
      "15 [D loss: 0.326220, acc.: 85.94%] [G loss: 0.017200]\n",
      "16 [D loss: 0.257717, acc.: 89.06%] [G loss: 0.022340]\n",
      "17 [D loss: 0.212927, acc.: 89.06%] [G loss: 0.013320]\n",
      "18 [D loss: 0.310248, acc.: 84.38%] [G loss: 0.014101]\n",
      "19 [D loss: 0.293261, acc.: 82.81%] [G loss: 0.010860]\n",
      "20 [D loss: 0.282043, acc.: 85.94%] [G loss: 0.016019]\n",
      "21 [D loss: 0.296477, acc.: 87.50%] [G loss: 0.011715]\n",
      "22 [D loss: 0.301604, acc.: 85.94%] [G loss: 0.008519]\n",
      "23 [D loss: 0.233435, acc.: 90.62%] [G loss: 0.011402]\n",
      "24 [D loss: 0.239263, acc.: 87.50%] [G loss: 0.015613]\n",
      "25 [D loss: 0.309505, acc.: 81.25%] [G loss: 0.019200]\n",
      "26 [D loss: 0.187044, acc.: 90.62%] [G loss: 0.006190]\n",
      "27 [D loss: 0.262714, acc.: 87.50%] [G loss: 0.007721]\n",
      "28 [D loss: 0.291055, acc.: 82.81%] [G loss: 0.007828]\n",
      "29 [D loss: 0.261622, acc.: 87.50%] [G loss: 0.014772]\n",
      "30 [D loss: 0.176277, acc.: 90.62%] [G loss: 0.008294]\n",
      "31 [D loss: 0.204481, acc.: 92.19%] [G loss: 0.003288]\n",
      "32 [D loss: 0.197653, acc.: 92.19%] [G loss: 0.009670]\n",
      "33 [D loss: 0.239540, acc.: 87.50%] [G loss: 0.005011]\n",
      "34 [D loss: 0.161997, acc.: 92.19%] [G loss: 0.004057]\n",
      "35 [D loss: 0.235371, acc.: 84.38%] [G loss: 0.002506]\n",
      "36 [D loss: 0.150089, acc.: 92.19%] [G loss: 0.002592]\n",
      "37 [D loss: 0.174763, acc.: 93.75%] [G loss: 0.004591]\n",
      "38 [D loss: 0.185451, acc.: 89.06%] [G loss: 0.001614]\n",
      "39 [D loss: 0.148152, acc.: 90.62%] [G loss: 0.001725]\n",
      "40 [D loss: 0.212649, acc.: 87.50%] [G loss: 0.001327]\n",
      "41 [D loss: 0.146707, acc.: 93.75%] [G loss: 0.003867]\n",
      "42 [D loss: 0.182849, acc.: 93.75%] [G loss: 0.001735]\n",
      "43 [D loss: 0.102829, acc.: 98.44%] [G loss: 0.003797]\n",
      "44 [D loss: 0.192503, acc.: 92.19%] [G loss: 0.003499]\n",
      "45 [D loss: 0.077611, acc.: 98.44%] [G loss: 0.000581]\n",
      "46 [D loss: 0.096698, acc.: 96.88%] [G loss: 0.001133]\n",
      "47 [D loss: 0.230028, acc.: 87.50%] [G loss: 0.003970]\n",
      "48 [D loss: 0.172888, acc.: 87.50%] [G loss: 0.002231]\n",
      "49 [D loss: 0.118167, acc.: 96.88%] [G loss: 0.001548]\n",
      "[+] \n",
      "Training the model with DT classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_161 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " dense_248 (Dense)           (None, 128)               17408     \n",
      "                                                                 \n",
      " dense_249 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_250 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_64 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_162 (InputLayer)         [(None, 135)]        0           []                               \n",
      "                                                                                                  \n",
      " input_163 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_32 (Concatenate)   (None, 235)          0           ['input_162[0][0]',              \n",
      "                                                                  'input_163[0][0]']              \n",
      "                                                                                                  \n",
      " dense_252 (Dense)              (None, 64)           15104       ['concatenate_32[0][0]']         \n",
      "                                                                                                  \n",
      " dense_253 (Dense)              (None, 64)           4160        ['dense_252[0][0]']              \n",
      "                                                                                                  \n",
      " dense_254 (Dense)              (None, 64)           4160        ['dense_253[0][0]']              \n",
      "                                                                                                  \n",
      " dense_255 (Dense)              (None, 128)          8320        ['dense_254[0][0]']              \n",
      "                                                                                                  \n",
      " dense_256 (Dense)              (None, 135)          17415       ['dense_255[0][0]']              \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 135)          0           ['dense_256[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_32 (Maximum)           (None, 135)          0           ['input_162[0][0]',              \n",
      "                                                                  'activation_65[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,159\n",
      "Trainable params: 49,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.690095, acc.: 62.50%] [G loss: 0.432778]\n",
      "1 [D loss: 0.765274, acc.: 64.06%] [G loss: 0.354228]\n",
      "2 [D loss: 0.679732, acc.: 68.75%] [G loss: 0.269914]\n",
      "3 [D loss: 0.648706, acc.: 67.19%] [G loss: 0.209908]\n",
      "4 [D loss: 0.504976, acc.: 75.00%] [G loss: 0.139696]\n",
      "5 [D loss: 0.554828, acc.: 71.88%] [G loss: 0.078319]\n",
      "6 [D loss: 0.549389, acc.: 70.31%] [G loss: 0.163601]\n",
      "7 [D loss: 0.545440, acc.: 68.75%] [G loss: 0.098149]\n",
      "8 [D loss: 0.460388, acc.: 78.12%] [G loss: 0.067063]\n",
      "9 [D loss: 0.635737, acc.: 68.75%] [G loss: 0.067143]\n",
      "10 [D loss: 0.333351, acc.: 84.38%] [G loss: 0.045121]\n",
      "11 [D loss: 0.478580, acc.: 75.00%] [G loss: 0.060388]\n",
      "12 [D loss: 0.533470, acc.: 70.31%] [G loss: 0.036205]\n",
      "13 [D loss: 0.512572, acc.: 75.00%] [G loss: 0.037114]\n",
      "14 [D loss: 0.521328, acc.: 79.69%] [G loss: 0.111014]\n",
      "15 [D loss: 0.375378, acc.: 84.38%] [G loss: 0.037346]\n",
      "16 [D loss: 0.582690, acc.: 64.06%] [G loss: 0.065485]\n",
      "17 [D loss: 0.477936, acc.: 75.00%] [G loss: 0.090068]\n",
      "18 [D loss: 0.536269, acc.: 76.56%] [G loss: 0.045376]\n",
      "19 [D loss: 0.485037, acc.: 76.56%] [G loss: 0.064555]\n",
      "20 [D loss: 0.346008, acc.: 84.38%] [G loss: 0.041205]\n",
      "21 [D loss: 0.324024, acc.: 81.25%] [G loss: 0.034913]\n",
      "22 [D loss: 0.455265, acc.: 78.12%] [G loss: 0.067796]\n",
      "23 [D loss: 0.263960, acc.: 87.50%] [G loss: 0.065370]\n",
      "24 [D loss: 0.425284, acc.: 81.25%] [G loss: 0.072240]\n",
      "25 [D loss: 0.476298, acc.: 81.25%] [G loss: 0.052247]\n",
      "26 [D loss: 0.289807, acc.: 89.06%] [G loss: 0.040384]\n",
      "27 [D loss: 0.527336, acc.: 71.88%] [G loss: 0.068798]\n",
      "28 [D loss: 0.415982, acc.: 78.12%] [G loss: 0.071058]\n",
      "29 [D loss: 0.240620, acc.: 92.19%] [G loss: 0.070709]\n",
      "30 [D loss: 0.463380, acc.: 78.12%] [G loss: 0.144526]\n",
      "31 [D loss: 0.503779, acc.: 85.94%] [G loss: 0.063713]\n",
      "32 [D loss: 0.322868, acc.: 84.38%] [G loss: 0.073923]\n",
      "33 [D loss: 0.370742, acc.: 79.69%] [G loss: 0.077346]\n",
      "34 [D loss: 0.286472, acc.: 84.38%] [G loss: 0.061754]\n",
      "35 [D loss: 0.317942, acc.: 82.81%] [G loss: 0.076491]\n",
      "36 [D loss: 0.388163, acc.: 81.25%] [G loss: 0.079594]\n",
      "37 [D loss: 0.414177, acc.: 75.00%] [G loss: 0.088695]\n",
      "38 [D loss: 0.256526, acc.: 84.38%] [G loss: 0.030745]\n",
      "39 [D loss: 0.242361, acc.: 87.50%] [G loss: 0.083024]\n",
      "40 [D loss: 0.344349, acc.: 82.81%] [G loss: 0.069919]\n",
      "41 [D loss: 0.440401, acc.: 76.56%] [G loss: 0.101892]\n",
      "42 [D loss: 0.412896, acc.: 78.12%] [G loss: 0.139180]\n",
      "43 [D loss: 0.457641, acc.: 78.12%] [G loss: 0.048341]\n",
      "44 [D loss: 0.280985, acc.: 89.06%] [G loss: 0.150355]\n",
      "45 [D loss: 0.391224, acc.: 78.12%] [G loss: 0.163932]\n",
      "46 [D loss: 0.314167, acc.: 81.25%] [G loss: 0.074011]\n",
      "47 [D loss: 0.226337, acc.: 85.94%] [G loss: 0.112181]\n",
      "48 [D loss: 0.245485, acc.: 89.06%] [G loss: 0.056861]\n",
      "49 [D loss: 0.369495, acc.: 82.81%] [G loss: 0.059400]\n",
      "[+] \n",
      "Training the model with GB classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_166 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " dense_257 (Dense)           (None, 128)               17408     \n",
      "                                                                 \n",
      " dense_258 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_259 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_260 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_66 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_167 (InputLayer)         [(None, 135)]        0           []                               \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_33 (Concatenate)   (None, 235)          0           ['input_167[0][0]',              \n",
      "                                                                  'input_168[0][0]']              \n",
      "                                                                                                  \n",
      " dense_261 (Dense)              (None, 64)           15104       ['concatenate_33[0][0]']         \n",
      "                                                                                                  \n",
      " dense_262 (Dense)              (None, 64)           4160        ['dense_261[0][0]']              \n",
      "                                                                                                  \n",
      " dense_263 (Dense)              (None, 64)           4160        ['dense_262[0][0]']              \n",
      "                                                                                                  \n",
      " dense_264 (Dense)              (None, 128)          8320        ['dense_263[0][0]']              \n",
      "                                                                                                  \n",
      " dense_265 (Dense)              (None, 135)          17415       ['dense_264[0][0]']              \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 135)          0           ['dense_265[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_33 (Maximum)           (None, 135)          0           ['input_167[0][0]',              \n",
      "                                                                  'activation_67[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,159\n",
      "Trainable params: 49,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.679908, acc.: 62.50%] [G loss: 0.461026]\n",
      "1 [D loss: 0.621677, acc.: 64.06%] [G loss: 0.246940]\n",
      "2 [D loss: 0.663720, acc.: 60.94%] [G loss: 0.152134]\n",
      "3 [D loss: 0.689886, acc.: 56.25%] [G loss: 0.113220]\n",
      "4 [D loss: 0.697516, acc.: 56.25%] [G loss: 0.086191]\n",
      "5 [D loss: 0.524102, acc.: 79.69%] [G loss: 0.062022]\n",
      "6 [D loss: 0.428089, acc.: 78.12%] [G loss: 0.044718]\n",
      "7 [D loss: 0.545703, acc.: 68.75%] [G loss: 0.030191]\n",
      "8 [D loss: 0.539747, acc.: 65.62%] [G loss: 0.036914]\n",
      "9 [D loss: 0.455226, acc.: 76.56%] [G loss: 0.034361]\n",
      "10 [D loss: 0.481125, acc.: 76.56%] [G loss: 0.027162]\n",
      "11 [D loss: 0.503957, acc.: 71.88%] [G loss: 0.012930]\n",
      "12 [D loss: 0.511769, acc.: 75.00%] [G loss: 0.018751]\n",
      "13 [D loss: 0.386989, acc.: 84.38%] [G loss: 0.022618]\n",
      "14 [D loss: 0.419117, acc.: 78.12%] [G loss: 0.013668]\n",
      "15 [D loss: 0.552291, acc.: 67.19%] [G loss: 0.021677]\n",
      "16 [D loss: 0.361350, acc.: 85.94%] [G loss: 0.014778]\n",
      "17 [D loss: 0.392201, acc.: 78.12%] [G loss: 0.013566]\n",
      "18 [D loss: 0.417415, acc.: 81.25%] [G loss: 0.013985]\n",
      "19 [D loss: 0.359538, acc.: 76.56%] [G loss: 0.012627]\n",
      "20 [D loss: 0.333505, acc.: 85.94%] [G loss: 0.011654]\n",
      "21 [D loss: 0.393691, acc.: 82.81%] [G loss: 0.012411]\n",
      "22 [D loss: 0.266754, acc.: 87.50%] [G loss: 0.008441]\n",
      "23 [D loss: 0.374437, acc.: 75.00%] [G loss: 0.011319]\n",
      "24 [D loss: 0.382898, acc.: 81.25%] [G loss: 0.016508]\n",
      "25 [D loss: 0.335818, acc.: 82.81%] [G loss: 0.005746]\n",
      "26 [D loss: 0.330551, acc.: 85.94%] [G loss: 0.014061]\n",
      "27 [D loss: 0.333608, acc.: 87.50%] [G loss: 0.006124]\n",
      "28 [D loss: 0.254290, acc.: 85.94%] [G loss: 0.002981]\n",
      "29 [D loss: 0.250443, acc.: 85.94%] [G loss: 0.002208]\n",
      "30 [D loss: 0.308381, acc.: 84.38%] [G loss: 0.003377]\n",
      "31 [D loss: 0.292819, acc.: 84.38%] [G loss: 0.006277]\n",
      "32 [D loss: 0.479274, acc.: 78.12%] [G loss: 0.005907]\n",
      "33 [D loss: 0.328725, acc.: 85.94%] [G loss: 0.003992]\n",
      "34 [D loss: 0.176528, acc.: 96.88%] [G loss: 0.014168]\n",
      "35 [D loss: 0.316218, acc.: 85.94%] [G loss: 0.006678]\n",
      "36 [D loss: 0.190178, acc.: 89.06%] [G loss: 0.004126]\n",
      "37 [D loss: 0.261166, acc.: 89.06%] [G loss: 0.001112]\n",
      "38 [D loss: 0.349747, acc.: 79.69%] [G loss: 0.003270]\n",
      "39 [D loss: 0.286517, acc.: 84.38%] [G loss: 0.005380]\n",
      "40 [D loss: 0.293798, acc.: 84.38%] [G loss: 0.004655]\n",
      "41 [D loss: 0.244889, acc.: 89.06%] [G loss: 0.002150]\n",
      "42 [D loss: 0.311514, acc.: 82.81%] [G loss: 0.001873]\n",
      "43 [D loss: 0.414869, acc.: 78.12%] [G loss: 0.006567]\n",
      "44 [D loss: 0.272929, acc.: 85.94%] [G loss: 0.016606]\n",
      "45 [D loss: 0.317163, acc.: 90.62%] [G loss: 0.005956]\n",
      "46 [D loss: 0.264702, acc.: 90.62%] [G loss: 0.006289]\n",
      "47 [D loss: 0.297923, acc.: 90.62%] [G loss: 0.002880]\n",
      "48 [D loss: 0.260744, acc.: 92.19%] [G loss: 0.008114]\n",
      "49 [D loss: 0.274580, acc.: 89.06%] [G loss: 0.006603]\n",
      "[+] \n",
      "Training the model with Ensem classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_171 (InputLayer)      [(None, 135)]             0         \n",
      "                                                                 \n",
      " dense_266 (Dense)           (None, 128)               17408     \n",
      "                                                                 \n",
      " dense_267 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 1)                 129       \n",
      "                                                                 \n",
      " activation_68 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_172 (InputLayer)         [(None, 135)]        0           []                               \n",
      "                                                                                                  \n",
      " input_173 (InputLayer)         [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_34 (Concatenate)   (None, 235)          0           ['input_172[0][0]',              \n",
      "                                                                  'input_173[0][0]']              \n",
      "                                                                                                  \n",
      " dense_270 (Dense)              (None, 64)           15104       ['concatenate_34[0][0]']         \n",
      "                                                                                                  \n",
      " dense_271 (Dense)              (None, 64)           4160        ['dense_270[0][0]']              \n",
      "                                                                                                  \n",
      " dense_272 (Dense)              (None, 64)           4160        ['dense_271[0][0]']              \n",
      "                                                                                                  \n",
      " dense_273 (Dense)              (None, 128)          8320        ['dense_272[0][0]']              \n",
      "                                                                                                  \n",
      " dense_274 (Dense)              (None, 135)          17415       ['dense_273[0][0]']              \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 135)          0           ['dense_274[0][0]']              \n",
      "                                                                                                  \n",
      " maximum_34 (Maximum)           (None, 135)          0           ['input_172[0][0]',              \n",
      "                                                                  'activation_69[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 49,159\n",
      "Trainable params: 49,159\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.646674, acc.: 57.81%] [G loss: 0.583442]\n",
      "1 [D loss: 0.615751, acc.: 60.94%] [G loss: 0.273131]\n",
      "2 [D loss: 0.596145, acc.: 62.50%] [G loss: 0.214602]\n",
      "3 [D loss: 0.647206, acc.: 57.81%] [G loss: 0.172373]\n",
      "4 [D loss: 0.627857, acc.: 59.38%] [G loss: 0.137435]\n",
      "5 [D loss: 0.515504, acc.: 64.06%] [G loss: 0.114849]\n",
      "6 [D loss: 0.473503, acc.: 71.88%] [G loss: 0.055633]\n",
      "7 [D loss: 0.568182, acc.: 59.38%] [G loss: 0.063748]\n",
      "8 [D loss: 0.523883, acc.: 67.19%] [G loss: 0.068803]\n",
      "9 [D loss: 0.528360, acc.: 64.06%] [G loss: 0.038994]\n",
      "10 [D loss: 0.420811, acc.: 71.88%] [G loss: 0.057028]\n",
      "11 [D loss: 0.450001, acc.: 73.44%] [G loss: 0.040263]\n",
      "12 [D loss: 0.461883, acc.: 68.75%] [G loss: 0.044124]\n",
      "13 [D loss: 0.434053, acc.: 70.31%] [G loss: 0.048292]\n",
      "14 [D loss: 0.408226, acc.: 76.56%] [G loss: 0.023762]\n",
      "15 [D loss: 0.481794, acc.: 73.44%] [G loss: 0.030820]\n",
      "16 [D loss: 0.385286, acc.: 78.12%] [G loss: 0.033851]\n",
      "17 [D loss: 0.434039, acc.: 75.00%] [G loss: 0.030387]\n",
      "18 [D loss: 0.349531, acc.: 79.69%] [G loss: 0.015460]\n",
      "19 [D loss: 0.366228, acc.: 78.12%] [G loss: 0.032112]\n",
      "20 [D loss: 0.267175, acc.: 84.38%] [G loss: 0.009079]\n",
      "21 [D loss: 0.277464, acc.: 84.38%] [G loss: 0.008855]\n",
      "22 [D loss: 0.169329, acc.: 95.31%] [G loss: 0.005655]\n",
      "23 [D loss: 0.229817, acc.: 89.06%] [G loss: 0.019894]\n",
      "24 [D loss: 0.261894, acc.: 89.06%] [G loss: 0.013559]\n",
      "25 [D loss: 0.370352, acc.: 89.06%] [G loss: 0.047784]\n",
      "26 [D loss: 0.314610, acc.: 85.94%] [G loss: 0.006627]\n",
      "27 [D loss: 0.221284, acc.: 92.19%] [G loss: 0.006883]\n",
      "28 [D loss: 0.375087, acc.: 84.38%] [G loss: 0.011164]\n",
      "29 [D loss: 0.342443, acc.: 87.50%] [G loss: 0.002916]\n",
      "30 [D loss: 0.245011, acc.: 92.19%] [G loss: 0.016857]\n",
      "31 [D loss: 0.256515, acc.: 89.06%] [G loss: 0.004314]\n",
      "32 [D loss: 0.212528, acc.: 90.62%] [G loss: 0.005574]\n",
      "33 [D loss: 0.229487, acc.: 93.75%] [G loss: 0.005171]\n",
      "34 [D loss: 0.242678, acc.: 92.19%] [G loss: 0.011087]\n",
      "35 [D loss: 0.223699, acc.: 92.19%] [G loss: 0.007730]\n",
      "36 [D loss: 0.310235, acc.: 81.25%] [G loss: 0.007130]\n",
      "37 [D loss: 0.177973, acc.: 95.31%] [G loss: 0.009047]\n",
      "38 [D loss: 0.172682, acc.: 93.75%] [G loss: 0.009901]\n",
      "39 [D loss: 0.199190, acc.: 92.19%] [G loss: 0.004700]\n",
      "40 [D loss: 0.174682, acc.: 93.75%] [G loss: 0.001638]\n",
      "41 [D loss: 0.157363, acc.: 95.31%] [G loss: 0.005263]\n",
      "42 [D loss: 0.215699, acc.: 92.19%] [G loss: 0.004243]\n",
      "43 [D loss: 0.203558, acc.: 95.31%] [G loss: 0.003464]\n",
      "44 [D loss: 0.170169, acc.: 95.31%] [G loss: 0.010923]\n",
      "45 [D loss: 0.155339, acc.: 98.44%] [G loss: 0.001880]\n",
      "46 [D loss: 0.298687, acc.: 92.19%] [G loss: 0.002545]\n",
      "47 [D loss: 0.231410, acc.: 93.75%] [G loss: 0.008774]\n",
      "48 [D loss: 0.162233, acc.: 98.44%] [G loss: 0.001465]\n",
      "49 [D loss: 0.162689, acc.: 95.31%] [G loss: 0.004744]\n",
      "=====================\n",
      "{'SVM': 0.17202455550432205, 'SGD': 0.11816747300326824, 'DT': 0.36949513480067253, 'GB': 0.2745802402496338, 'Ensem': 0.16268927976489067}\n",
      "=====================\n",
      "{'SVM': 93.75, 'SGD': 96.875, 'DT': 82.8125, 'GB': 89.0625, 'Ensem': 95.3125}\n",
      "=====================\n",
      "{'SVM': 0.0009889311622828245, 'SGD': 0.0015482198214158416, 'DT': 0.0593997947871685, 'GB': 0.006602793466299772, 'Ensem': 0.004743809811770916}\n"
     ]
    }
   ],
   "source": [
    "# load the classifier\n",
    "for classifier in [ 'SVM', 'SGD', 'DT', 'GB', 'Ensem']: \n",
    "    print('[+] \\nTraining the model with {} classifier\\n'.format(classifier))\n",
    "    malgan = MalGAN(blackbox=classifier, X=X, Y=Y, threshold = 179)\n",
    "    d_loss, acc, g_loss = malgan.train(epochs=50, batch_size=32)\n",
    "\n",
    "    D_loss_dict[classifier] = d_loss\n",
    "    Acc_dict[classifier] = acc \n",
    "    G_loss_dict[classifier] = g_loss\n",
    "\n",
    "\n",
    "print('=====================')\n",
    "print(D_loss_dict)\n",
    "print('=====================')\n",
    "print(Acc_dict)\n",
    "print('=====================')\n",
    "print(G_loss_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_dict = {}\n",
    "\n",
    "for key, value in D_loss_dict.items():\n",
    "    matrix_dict[key] = []\n",
    "\n",
    "\n",
    "for key, value in D_loss_dict.items():\n",
    "    matrix_dict[key].append(D_loss_dict[key])\n",
    "    matrix_dict[key].append(Acc_dict[key])\n",
    "    matrix_dict[key].append(G_loss_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SVM': [0.17202455550432205, 93.75, 0.0009889311622828245],\n",
       " 'SGD': [0.11816747300326824, 96.875, 0.0015482198214158416],\n",
       " 'DT': [0.36949513480067253, 82.8125, 0.0593997947871685],\n",
       " 'GB': [0.2745802402496338, 89.0625, 0.006602793466299772],\n",
       " 'Ensem': [0.16268927976489067, 95.3125, 0.004743809811770916]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>Ensem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_Loss</th>\n",
       "      <td>0.172025</td>\n",
       "      <td>0.118167</td>\n",
       "      <td>0.369495</td>\n",
       "      <td>0.274580</td>\n",
       "      <td>0.162689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>93.750000</td>\n",
       "      <td>96.875000</td>\n",
       "      <td>82.812500</td>\n",
       "      <td>89.062500</td>\n",
       "      <td>95.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_Loss</th>\n",
       "      <td>0.000989</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.059400</td>\n",
       "      <td>0.006603</td>\n",
       "      <td>0.004744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVM        SGD         DT         GB      Ensem\n",
       "D_Loss   0.172025   0.118167   0.369495   0.274580   0.162689\n",
       "Acc     93.750000  96.875000  82.812500  89.062500  95.312500\n",
       "G_Loss   0.000989   0.001548   0.059400   0.006603   0.004744"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(matrix_dict, orient='columns') \n",
    "df.index= list([ 'D_Loss', 'Acc', 'G_Loss'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(df, '128_4_ran_matrix_0.5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fecd871876602184e2def9d040398806a20c493ba8c7291bbd5a5358628e6cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the random seed\n",
    "global seed\n",
    "seed = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the dataset fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from Feature-Selector\n",
    "X = np.loadtxt('../dataset/matrix/X_fs.csv')\n",
    "Y = np.loadtxt('../dataset/matrix/Y_str.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset dict\n",
    "dataset_type = {'dataset': ['fs']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dict to save the result\n",
    "confusion_matrix_dict = {}\n",
    "roc_auc_score_dict = {}\n",
    "f1_score_dict = {}\n",
    "accuracy_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the realization of BaggingClassifier\n",
    "def Bag_classifier(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    accuracy_svc = []\n",
    "    confusion_matrix_svc = []\n",
    "    roc_auc_score_svc = []\n",
    "    f1_score_svc = []\n",
    "    \n",
    "    clf = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    accuracy = np.round(clf.score(X_test, y_test),6)\n",
    "    roc_auc_score_value = np.round(roc_auc_score(y_test, y_pred),6)\n",
    "    f1_score_value = np.round(f1_score(y_test, y_pred),6)\n",
    "    \n",
    "    print('The confusion matrix for BaggingClassifier model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for BaggingClassifier model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for BaggingClassifier model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for BaggingClassifier model is [[26  3]\n",
      " [ 3 49]]\n",
      "\n",
      "The roc_aux_score for BaggingClassifier model is 0.91943\n",
      "\n",
      "The f1_score for BaggingClassifier model is 0.942308\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "\n",
    "value11, value12, value13, value14  = Bag_classifier(X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "confusion_matrix_dict['BaggingClassifier'] = value11\n",
    "roc_auc_score_dict['BaggingClassifier'] = value12\n",
    "f1_score_dict['BaggingClassifier'] = value13\n",
    "accuracy_dict['BaggingClassifier'] = value14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the realization of RandomForestClassifier\n",
    "def RF_model(X_trian, X_test, y_train, y_test):\n",
    "    clf = RandomForestClassifier(max_depth=2, random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "\n",
    "    accuracy = np.round(clf.score(X_test, y_test), 6)\n",
    "    \n",
    "    roc_auc_score_value = np.round(roc_auc_score(y_test, y_pred),6)\n",
    "    f1_score_value = np.round(f1_score(y_test, y_pred),6)\n",
    "    \n",
    "    \n",
    "    print('The confusion matrix for RandomForestClassifier model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for RandomForestClassifier model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for RandomForestClassifier model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for RandomForestClassifier model is [[25  4]\n",
      " [ 5 47]]\n",
      "\n",
      "The roc_aux_score for RandomForestClassifier model is 0.882958\n",
      "\n",
      "The f1_score for RandomForestClassifier model is 0.912621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value21, value22, value23, value24 = RF_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "confusion_matrix_dict['RandomForestClassifier'] = value21\n",
    "roc_auc_score_dict['RandomForestClassifier'] = value22\n",
    "f1_score_dict['RandomForestClassifier'] = value23\n",
    "accuracy_dict['RandomForestClassifier'] = value24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the realization of AdaBoostClassifier\n",
    "def AdaBoost_model(X_trian, X_test, y_train, y_test):\n",
    "    clf = AdaBoostClassifier(n_estimators=100, random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = np.round(clf.score(X_test, y_test), 6)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = np.round(roc_auc_score(y_test, y_pred),6)\n",
    "    f1_score_value = np.round(f1_score(y_test, y_pred),6)\n",
    "        \n",
    "    print('The confusion matrix for AdaBoost_model model is {}\\n'.format(confusion_matrix(y_test, y_pred, labels=[0,1])))\n",
    "    print('The roc_aux_score for AdaBoost_model model is {}\\n'.format(roc_auc_score(y_test, y_pred)))\n",
    "    print('The f1_score for AdaBoost_model model is {}\\n'.format(f1_score(y_test, y_pred)))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for RandomForestClassifier model is [[25  4]\n",
      " [ 5 47]]\n",
      "\n",
      "The roc_aux_score for RandomForestClassifier model is 0.882958\n",
      "\n",
      "The f1_score for RandomForestClassifier model is 0.912621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "value31, value32, value33, value34 = RF_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "confusion_matrix_dict['AdaBoostClassifier'] = value31\n",
    "roc_auc_score_dict['AdaBoostClassifier'] = value32\n",
    "f1_score_dict['AdaBoostClassifier'] = value33\n",
    "accuracy_dict['AdaBoostClassifier'] = value34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the realization of GradientBoostingClassifier\n",
    "def GradientBoost_model(X_trian, X_test, y_train, y_test):\n",
    "    clf = GradientBoostingClassifier(n_estimators=100, random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = np.round(clf.score(X_test, y_test),6)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = np.round(roc_auc_score(y_test, y_pred), 6)\n",
    "    f1_score_value = np.round(f1_score(y_test, y_pred),6)\n",
    "    \n",
    "    print('The confusion matrix for GradientBoost_model model is {}\\n'.format(confusion_matrix(y_test, y_pred, labels=[0,1])))\n",
    "    print('The roc_aux_score for GradientBoost_model model is {}\\n'.format(roc_auc_score(y_test, y_pred)))\n",
    "    print('The f1_score for GradientBoost_model model is {}\\n'.format(f1_score(y_test, y_pred)))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for GradientBoost_model model is [[26  3]\n",
      " [ 1 51]]\n",
      "\n",
      "The roc_aux_score for GradientBoost_model model is 0.9386604774535809\n",
      "\n",
      "The f1_score for GradientBoost_model model is 0.9622641509433962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value41, value42, value43, value44 = GradientBoost_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "confusion_matrix_dict['GradientBoostingClassifier'] = value41\n",
    "roc_auc_score_dict['GradientBoostingClassifier'] = value42\n",
    "f1_score_dict['GradientBoostingClassifier'] = value43\n",
    "accuracy_dict['GradientBoostingClassifier'] = value44   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the metrics dataframe for ensemble classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>[[26, 3], [3, 49]]</td>\n",
       "      <td>[[25, 4], [5, 47]]</td>\n",
       "      <td>[[25, 4], [5, 47]]</td>\n",
       "      <td>[[26, 3], [1, 51]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BaggingClassifier RandomForestClassifier  AdaBoostClassifier  \\\n",
       "data type                                                                  \n",
       "fs         [[26, 3], [3, 49]]     [[25, 4], [5, 47]]  [[25, 4], [5, 47]]   \n",
       "\n",
       "          GradientBoostingClassifier  \n",
       "data type                             \n",
       "fs                [[26, 3], [1, 51]]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Confusion_Matrix\n",
    "df_confusion_matrix = pd.DataFrame([confusion_matrix_dict], index=[0])\n",
    "df_confusion_matrix['data type'] = dataset_type['dataset']\n",
    "df_confusion_matrix.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>0.91943</td>\n",
       "      <td>0.882958</td>\n",
       "      <td>0.882958</td>\n",
       "      <td>0.93866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BaggingClassifier  RandomForestClassifier  AdaBoostClassifier  \\\n",
       "data type                                                                  \n",
       "fs                   0.91943                0.882958            0.882958   \n",
       "\n",
       "           GradientBoostingClassifier  \n",
       "data type                              \n",
       "fs                            0.93866  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Roc_Auc_Score\n",
    "df_roc_auc_score = pd.DataFrame([roc_auc_score_dict])\n",
    "df_roc_auc_score['data type'] = dataset_type['dataset']\n",
    "df_roc_auc_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.962264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BaggingClassifier  RandomForestClassifier  AdaBoostClassifier  \\\n",
       "data type                                                                  \n",
       "fs                  0.942308                0.912621            0.912621   \n",
       "\n",
       "           GradientBoostingClassifier  \n",
       "data type                              \n",
       "fs                           0.962264  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. F1_Score\n",
    "df_f1_score = pd.DataFrame([f1_score_dict])\n",
    "df_f1_score['data type'] = dataset_type['dataset']\n",
    "df_f1_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BaggingClassifier</th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fs</th>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.950617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BaggingClassifier  RandomForestClassifier  AdaBoostClassifier  \\\n",
       "data type                                                                  \n",
       "fs                  0.925926                0.888889            0.888889   \n",
       "\n",
       "           GradientBoostingClassifier  \n",
       "data type                              \n",
       "fs                           0.950617  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Accuracy\n",
    "df_accuracy = pd.DataFrame([accuracy_dict])\n",
    "df_accuracy['data type'] = dataset_type['dataset']\n",
    "df_accuracy.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the matrix\n",
    "df = pd.DataFrame(columns=df_accuracy.columns.values)\n",
    "# df = df.append(df_confusion_matrix, ignore_index=True)\n",
    "df = df.append(df_roc_auc_score, ignore_index=True)\n",
    "df = df.append(df_f1_score, ignore_index=True)\n",
    "df = df.append(df_accuracy, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index= list([ 'roc_auc_score', 'f1_score', 'accuracy'])\n",
    "# with pd.option_context('display.max_rows', None):\n",
    "    # print(df['SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(df.drop('data type', axis=1), 'matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fecd871876602184e2def9d040398806a20c493ba8c7291bbd5a5358628e6cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

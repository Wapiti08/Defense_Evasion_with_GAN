{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=['regkey_opened','regkey_read','regkey_written','regkey_deleted','file_created',\n",
    "'file_opened','file_read','file_deleted','extfile_opened','extfile_read','extfile_created',\n",
    "'extfile_deleted','directory_created','dll_loaded','apistats','network','dropped','strings']\n",
    "len(file_name)\n",
    "\n",
    "feature_dict = {}\n",
    "for name in file_name:\n",
    "    feature_dict[name]=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_File_name_Reg(reg):\n",
    "    if 'RASMANCS' in reg:\n",
    "        r_split=reg.split(\"\\\\\")\n",
    "        new_reg=[]\n",
    "        for m in r_split:\n",
    "            if 'RASMANCS' in m:\n",
    "                m='RASMANCS'\n",
    "            new_reg.append(m)\n",
    "        new_reg=\"\\\\\".join(new_reg)\n",
    "        return new_reg\n",
    "    if 'RASAPI32' in reg:\n",
    "        r_split=reg.split(\"\\\\\")\n",
    "        new_reg=[]\n",
    "        for m in r_split:\n",
    "            if 'RASAPI32' in m:\n",
    "                m='RASAPI32'\n",
    "            new_reg.append(m)\n",
    "        new_reg=\"\\\\\".join(new_reg)\n",
    "        return new_reg\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Remove_PC_Name(path_name):\n",
    "    New_Path_Name=[]\n",
    "    if 'test' in path_name:\n",
    "        r_split=path_name.split(\"\\\\\")\n",
    "        for strings in r_split:\n",
    "            if 'test' in strings:\n",
    "                strings=\"guest\"\n",
    "            New_Path_Name.append(strings)\n",
    "        New_Path_Name=\"\\\\\".join(New_Path_Name)\n",
    "        return New_Path_Name\n",
    "    return path_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:25: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:25: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-5-ab7aace96d81>:6: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if name is 'apistats':\n",
      "<ipython-input-5-ab7aace96d81>:18: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif name is 'strings':\n",
      "<ipython-input-5-ab7aace96d81>:25: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  elif name is 'network':\n"
     ]
    }
   ],
   "source": [
    "def Extract_Features(data , file_list, feature_dict):\n",
    "    \n",
    "    file_name=file_list\n",
    "    for name in file_name:\n",
    "        # collect tha apistats values\n",
    "        if name is 'apistats':\n",
    "            if 'behavior' in data:\n",
    "                if 'apistats' in data['behavior']:\n",
    "                    for m in data['behavior']['apistats']:\n",
    "                # there are some number in json parsing therefore pid is initilize\n",
    "                        pid=m\n",
    "                        # get the string values in apistats\n",
    "                        api_data=data['behavior']['apistats'][pid]\n",
    "                    for api in api_data:\n",
    "                        feature_dict['apistats'].append(api)\n",
    "                        \n",
    "        # collect the strings values\n",
    "        elif name is 'strings':\n",
    "            if 'strings' in data:\n",
    "                for strrng in data['strings']:\n",
    "                    feature_dict['strings'].append(strrng)\n",
    "                    \n",
    "        \n",
    "        # collect the network values\n",
    "        elif name is 'network':\n",
    "            ipList=[]\n",
    "            if 'network' in data:\n",
    "                if 'udp' in data['network']:\n",
    "                    for indicies in data['network']['udp']:\n",
    "                        ipList.append(indicies['src'])\n",
    "                        ipList.append(indicies['dst'])\n",
    "                if 'hosts' in data['network']:\n",
    "                    for indicies in data['network']['hosts']:\n",
    "                        ipList.append(indicies)\n",
    "                ipList=list(set(ipList))\n",
    "                ips=[ip for ip in ipList if not (ip.startswith('192') or ip in ['224.0.0.252','8.8.8.8','239.255.255.250'])]\n",
    "                for ip in ips:\n",
    "                    feature_dict['network'].append(ip)\n",
    "        \n",
    "        # elif name is \"dropped\":     \n",
    "        #     # collect the dropped valueslif name is 'dropped':\n",
    "        #     if 'metadata' in data:\n",
    "        #         if 'output' in data['metadata']:\n",
    "        #             for m in data['metadata']['output']:\n",
    "        #                 if 'dropped' in m:\n",
    "        #                     c=0\n",
    "        #                     for drop_name in data['metadata']['output']['dropped']:\n",
    "        #                         if 'basename' in drop_name:\n",
    "        #                             for m in drop_name:\n",
    "        #                                 basename=data['metadata']['output']['dropped'][c]['basename']\n",
    "        #                                 if 'virusshare' not in basename:\n",
    "        #                                     r_split=basename.rsplit('.')\n",
    "        #                                     feature_dict['dropped'].append(str(r_split[-1]))\n",
    "        #                                 print('111111111111111')\n",
    "        #                                 print(feature_dict['dropped'])\n",
    "        #                         c+=1                   \n",
    "        # collect the ext\n",
    "        elif name.startswith('ext'):\n",
    "            if 'behavior' in data:\n",
    "                if 'summary' in data['behavior']:\n",
    "                    for m in data['behavior']['summary']:\n",
    "                        if str(name[3:]) in m:\n",
    "                            for key in data[\"behavior\"]['summary'][str(name[3:])]:\n",
    "                                key=Remove_PC_Name(key)\n",
    "                                r_split=key.rsplit('.')\n",
    "                                if 'VirusShare' not in r_split[-1]:\n",
    "                                   \n",
    "                                    feature_dict[str(name)].append(r_split[-1])\n",
    "\n",
    "        elif 'behavior' in data:\n",
    "            if 'summary' in data['behavior']:\n",
    "                for m in data['behavior']['summary']:\n",
    "                    if str(name) in m:\n",
    "                        for reg_key in data[\"behavior\"]['summary'][str(name)]:\n",
    "                            reg_key=Remove_File_name_Reg(reg_key)\n",
    "                            reg_key=Remove_PC_Name(reg_key)\n",
    "                            feature_dict[str(name)].append(reg_key)\n",
    "\n",
    "        # else:\n",
    "        #     continue\n",
    "    return feature_dict        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component to collect all unique features to a dict for the normal software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f_normal = open(\"E:/Analysis-on-GAN/dataset/feature_dict_normal.pkl\", 'wb')\n",
    "\n",
    "# for root, filepath, filename in os.walk(\"E:/Analysis-on-GAN/dataset/Normal\"):\n",
    "#     for report in filename:\n",
    "#         report = Path(root).joinpath(report).as_posix()\n",
    "#         print(report)\n",
    "#         with open(report,'r') as fr:\n",
    "#             data = json.load(fr)\n",
    "#             feature_dict_normal = Extract_Features(data , file_name, feature_dict)\n",
    "#     # filter the repeated values and lines\n",
    "#     for key, value in feature_dict_normal.items():\n",
    "#         feature_dict_normal[key]=set(value)\n",
    "#     pickle.dump(feature_dict_normal, f_normal)\n",
    "#             # for key, item in feature_dict.items():\n",
    "#             #     print('key: {} item: {}'.format(key, item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'regkey_opened': [],\n",
       " 'regkey_read': [],\n",
       " 'regkey_written': [],\n",
       " 'regkey_deleted': [],\n",
       " 'file_created': [],\n",
       " 'file_opened': [],\n",
       " 'file_read': [],\n",
       " 'file_deleted': [],\n",
       " 'extfile_opened': [],\n",
       " 'extfile_read': [],\n",
       " 'extfile_created': [],\n",
       " 'extfile_deleted': [],\n",
       " 'directory_created': [],\n",
       " 'dll_loaded': [],\n",
       " 'apistats': [],\n",
       " 'network': [],\n",
       " 'dropped': [],\n",
       " 'strings': []}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def htmlEscape(input):\n",
    "#     if not input:\n",
    "#         return input;\n",
    "#     input = input.replace(\"&\", \"&amp;\");\n",
    "#     input = input.replace(\"<\", \"&lt;\");\n",
    "#     input = input.replace(\">\", \"&gt;\");\n",
    "#     # input = input.replace(\" \", \"&nbsp;\");\n",
    "#     # input = input.replace(\"'\", \"&#39;\");\n",
    "#     # input = input.replace(\"\\\"\", \"&quot;\");\n",
    "#     input = input.replace(\"\\n\", \"<br/>\");\n",
    "#     return input\n",
    "feature_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component to collect all unique features to a dict for the ransomware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# f_ransom = open(\"E:/Analysis-on-GAN/dataset/feature_all_unique/feature_dict_ransom.pkl\", 'wb')\n",
    "# for root, filepath, filename in os.walk(\"E:/Analysis-on-GAN/dataset/Ransom\"):\n",
    "#     for report in filename:\n",
    "#         report = Path(root).joinpath(report).as_posix()\n",
    "#         print(report)\n",
    "#         with open(report,'r') as fr:\n",
    "#             # # handle the error Invalid \\uXXXX escape\n",
    "#             # regex = re.compile(r'\\\\(?![/u\"])')\n",
    "#             # fixed = regex.sub(r\"\\\\\\\\\", fr.read())\n",
    "#             # # handle the error Expecting ',' delimiter\n",
    "#             # fixed = fixed.replace(\"\\\\\",r\"\\\\\")\n",
    "#             # context = htmlEscape(fr.read())\n",
    "#             try:\n",
    "#                 data_ransom = json.loads(fr.read(), strict=False)\n",
    "#             except Exception as e:\n",
    "#                 print(e)\n",
    "#                 pass\n",
    "#             feature_dict_ransom = Extract_Features(data_ransom , file_name, feature_dict)\n",
    "\n",
    "#     for key, value in feature_dict_ransom.items():\n",
    "#         print(value)\n",
    "#         feature_dict_ransom[key]=set(value)\n",
    "\n",
    "#     pickle.dump(feature_dict_ransom, f_ransom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component to collect all registry values to pkl file for the ransomware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting property name enclosed in double quotes: line 317553 column 25 (char 13834725)\n",
      "Expecting ':' delimiter: line 4034254 column 31 (char 176305224)\n",
      "Expecting ',' delimiter: line 1449391 column 56 (char 63517875)\n",
      "Expecting ':' delimiter: line 908002 column 30 (char 61212619)\n",
      "Expecting value: line 316630 column 41 (char 14177507)\n",
      "Expecting property name enclosed in double quotes: line 229633 column 25 (char 10084493)\n",
      "Expecting ':' delimiter: line 54491 column 32 (char 3414594)\n",
      "Expecting value: line 16372 column 34 (char 915173)\n",
      "Expecting property name enclosed in double quotes: line 605342 column 29 (char 26541214)\n",
      "Expecting value: line 1095827 column 33 (char 48003467)\n",
      "Expecting ',' delimiter: line 470906 column 50 (char 20679853)\n",
      "Expecting ',' delimiter: line 863953 column 22 (char 42832086)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "registry_values_ransom = open(\"E:/Analysis-on-GAN/dataset/registry_values/registry_values_ransom.pkl\", 'wb')\n",
    "wanted_keys = ['regkey_opened','regkey_read','regkey_written','regkey_deleted']\n",
    "for root, filepath, filename in os.walk(\"E:/Analysis-on-GAN/dataset/Ransom\"):\n",
    "    for report in filename:\n",
    "        report = Path(root).joinpath(report).as_posix()\n",
    "        with open(report,'r') as fr:\n",
    "            try:\n",
    "                data_ransom = json.loads(fr.read(), strict=False)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            feature_dict_ransom = Extract_Features(data_ransom , file_name, feature_dict)\n",
    "    # extract all the registry related values\n",
    "    registry_values_dict = dict((key, feature_dict_ransom[key]) for key in wanted_keys if key in feature_dict_ransom)\n",
    "\n",
    "    pickle.dump(registry_values_dict, registry_values_ransom )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component to collect all registry values to pkl file for the normal software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry_values_normal = open(\"E:/Analysis-on-GAN/dataset/registry_values/registry_values_normal.pkl\", 'wb')\n",
    "wanted_keys = ['regkey_opened','regkey_read','regkey_written','regkey_deleted']\n",
    "for root, filepath, filename in os.walk(\"E:/Analysis-on-GAN/dataset/Normal\"):\n",
    "    for report in filename:\n",
    "        report = Path(root).joinpath(report).as_posix()\n",
    "        with open(report,'r') as fr:\n",
    "            try:\n",
    "                data_ransom = json.loads(fr.read(), strict=False)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "            feature_dict_normal = Extract_Features(data_ransom , file_name, feature_dict)\n",
    "    # extract all the registry related values\n",
    "    registry_values_normal_dict = dict((key, feature_dict_normal[key]) for key in wanted_keys if key in feature_dict_normal)\n",
    "\n",
    "    pickle.dump(registry_values_normal_dict, registry_values_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitdbd76ed984a5488496eb976b9e8b3b8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

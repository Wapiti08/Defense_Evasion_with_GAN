{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the evaluation libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "# import the processing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the random seed\n",
    "global seed\n",
    "seed = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the dataset, there are six types of dataset in total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from Feature-Selector\n",
    "selected_features = pd.read_pickle('../dataset/training_data/features_selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the label for all dataset\n",
    "label = selected_features['label']\n",
    "# label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 56)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_all = selected_features.iloc[:,1:-1]\n",
    "selected_features_all.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 2841)\n",
      "(333, 1772)\n"
     ]
    }
   ],
   "source": [
    "# get the data from three-Gram\n",
    "thr_gram_features = pd.read_pickle('../dataset/training_data/thr_gram_features.pkl')\n",
    "# bypass the label column\n",
    "thr_gram_features = thr_gram_features.iloc[:,:-1]\n",
    "print(thr_gram_features.values.shape)\n",
    "# get the data from four-Gram\n",
    "four_gram_features = pd.read_pickle('../dataset/training_data/four_gram_features.pkl')\n",
    "print(four_gram_features.values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(333, 1049)\n",
      "(333, 688)\n"
     ]
    }
   ],
   "source": [
    "# get the data from all TF-IDF features\n",
    "tf_idf_all = pd.read_pickle('../dataset/training_data/features_ran_all.pkl')\n",
    "# bypass the label column\n",
    "tf_idf_all = tf_idf_all.iloc[:,:-1]\n",
    "print(tf_idf_all.values.shape)\n",
    "# get the data from partial TF-IDF features\n",
    "tf_idf_part = pd.read_pickle('../dataset/training_data/features_ran_part.pkl')\n",
    "# bypass the label column\n",
    "tf_idf_part = tf_idf_part.iloc[:,:-1]\n",
    "print(tf_idf_part.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(333, 2297)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the united features\n",
    "united_features = pd.read_pickle('../dataset/training_data/united_features.pkl')\n",
    "united_features.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dataset dict\n",
    "dataset_dict = {\n",
    "    'selected_features': selected_features_all,\n",
    "    'thr_gram_features': thr_gram_features,\n",
    "    'four_gram_features': four_gram_features,\n",
    "    'tf_idf_all': tf_idf_all,\n",
    "    'tf_idf_part': tf_idf_part,\n",
    "    'united_features': united_features\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert the features into numpy data from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to create training and testing x and y from data\n",
    "def data_split(dataframe, label):\n",
    "    X = dataframe.values\n",
    "    y = label.values\n",
    "    # shuffle the data\n",
    "    X, y = shuffle(X, y, random_state = seed)\n",
    "    # split the data into training and testing data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the dict to save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_dict = {}\n",
    "roc_auc_score_dict = {}\n",
    "f1_score_dict = {}\n",
    "accuracy_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = {'dataset': ['feature_selection', 'thr_gram_features', 'four_gram_features', 'tf_idf_all', 'tf_idf_part', 'united_features']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the classifier model based on sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create svm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of SVM\n",
    "# The polynomial and RBF are especially useful when the data-points are not linearly separable.\n",
    "def SVC_model(X_train, X_test, y_train, y_test):\n",
    "    accuracy_svc = []\n",
    "    confusion_matrix_svc = []\n",
    "    roc_auc_score_svc = []\n",
    "    f1_score_svc = []\n",
    "    for kernel in ('linear', 'poly', 'rbf'):\n",
    "        clf = SVC(kernel = kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        \n",
    "        confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "        f1_score_value = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print('The confusion matrix for kernel {} is {}\\n'.format(kernel, confusion_matrix_value))\n",
    "        print('The roc_aux_score for kernel {} is {}\\n'.format(kernel,roc_auc_score_value))\n",
    "        print('The f1_score for kernel {} is {}\\n'.format(kernel, f1_score_value))\n",
    "        accuracy_svc.append(accuracy)\n",
    "        confusion_matrix_svc.append(confusion_matrix_value)\n",
    "        roc_auc_score_svc.append(roc_auc_score_value)\n",
    "        f1_score_svc.append(f1_score_value)\n",
    "        \n",
    "    return confusion_matrix_svc, roc_auc_score_svc, f1_score_svc, accuracy_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[41  1]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.988095238095238\n",
      "\n",
      "The f1_score for kernel poly is 0.9914529914529915\n",
      "\n",
      "The confusion matrix for kernel rbf is [[41  1]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 0.988095238095238\n",
      "\n",
      "The f1_score for kernel rbf is 0.9914529914529915\n",
      "\n",
      "The performace of features selected_features on the three kernels of scv is [1.0, 0.99, 0.99]\n",
      "\n",
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[37  5]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.9404761904761905\n",
      "\n",
      "The f1_score for kernel poly is 0.9586776859504132\n",
      "\n",
      "The confusion matrix for kernel rbf is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 1.0\n",
      "\n",
      "The f1_score for kernel rbf is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the three kernels of scv is [1.0, 0.95, 1.0]\n",
      "\n",
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[37  5]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.9404761904761905\n",
      "\n",
      "The f1_score for kernel poly is 0.9586776859504132\n",
      "\n",
      "The confusion matrix for kernel rbf is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 1.0\n",
      "\n",
      "The f1_score for kernel rbf is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the three kernels of scv is [1.0, 0.95, 1.0]\n",
      "\n",
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[36  6]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.9285714285714286\n",
      "\n",
      "The f1_score for kernel poly is 0.9508196721311475\n",
      "\n",
      "The confusion matrix for kernel rbf is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 1.0\n",
      "\n",
      "The f1_score for kernel rbf is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the three kernels of scv is [1.0, 0.94, 1.0]\n",
      "\n",
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[37  5]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.9404761904761905\n",
      "\n",
      "The f1_score for kernel poly is 0.9586776859504132\n",
      "\n",
      "The confusion matrix for kernel rbf is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 1.0\n",
      "\n",
      "The f1_score for kernel rbf is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the three kernels of scv is [1.0, 0.95, 1.0]\n",
      "\n",
      "The confusion matrix for kernel linear is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 1.0\n",
      "\n",
      "The f1_score for kernel linear is 1.0\n",
      "\n",
      "The confusion matrix for kernel poly is [[37  5]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.9404761904761905\n",
      "\n",
      "The f1_score for kernel poly is 0.9586776859504132\n",
      "\n",
      "The confusion matrix for kernel rbf is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 1.0\n",
      "\n",
      "The f1_score for kernel rbf is 1.0\n",
      "\n",
      "The performace of features united_features on the three kernels of scv is [1.0, 0.95, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value110, value120, value130, value140 = [], [], [], []\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value11, value12, value13, value14  = SVC_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value110.append(value11)\n",
    "    value120.append(value12)\n",
    "    value130.append(value13)\n",
    "    value140.append(value14)\n",
    "    print('The performace of features {} on the three kernels of scv is {}\\n'.format(key, value14))\n",
    "\n",
    "# write the metrics to dict\n",
    "confusion_matrix_dict['SVM'] = value110\n",
    "roc_auc_score_dict['SVM'] = value120\n",
    "f1_score_dict['SVM'] = value130\n",
    "accuracy_dict['SVM'] = value140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision Trees model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of Decision Trees\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for decision trees model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for decision trees model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for decision trees model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features selected_features on the decision trees model is 1.0\n",
      "\n",
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the decision trees model is 1.0\n",
      "\n",
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the decision trees model is 1.0\n",
      "\n",
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the decision trees model is 1.0\n",
      "\n",
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the decision trees model is 1.0\n",
      "\n",
      "The confusion matrix for decision trees model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 1.0\n",
      "\n",
      "The f1_score for decision trees model is 1.0\n",
      "\n",
      "The performace of features united_features on the decision trees model is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value210, value220, value230, value240 = [], [], [], []\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value21, value22, value23, value24 = decision_tree(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value210.append(value21)\n",
    "    value220.append(value22)\n",
    "    value230.append(value23)\n",
    "    value240.append(value24)\n",
    "    \n",
    "    print('The performace of features {} on the decision trees model is {}\\n'.format(key, value24))\n",
    "\n",
    "    \n",
    "confusion_matrix_dict['Decision Trees'] = value210\n",
    "roc_auc_score_dict['Decision Trees'] = value220\n",
    "f1_score_dict['Decision Trees'] = value230\n",
    "accuracy_dict['Decision Trees'] = value240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Naive Bayers model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of Naive Bayers \n",
    "def naive_bayers_model(X_train, X_test, y_train, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for Naive Bayers model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for Naive Bayers model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for Naive Bayers model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features selected_features on the naive bayers model is 1.0\n",
      "\n",
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the naive bayers model is 1.0\n",
      "\n",
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the naive bayers model is 1.0\n",
      "\n",
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the naive bayers model is 1.0\n",
      "\n",
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the naive bayers model is 1.0\n",
      "\n",
      "The confusion matrix for Naive Bayers model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 1.0\n",
      "\n",
      "The f1_score for Naive Bayers model is 1.0\n",
      "\n",
      "The performace of features united_features on the naive bayers model is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value310, value320, value330, value340 = [], [], [], []\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value31, value32, value33, value34 = naive_bayers_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value310.append(value31)\n",
    "    value320.append(value32)\n",
    "    value330.append(value33)\n",
    "    value340.append(value34)\n",
    "    \n",
    "    print('The performace of features {} on the naive bayers model is {}\\n'.format(key, value34))\n",
    "\n",
    "confusion_matrix_dict['Naive Bayers'] = value310\n",
    "roc_auc_score_dict['Naive Bayers'] = value320\n",
    "f1_score_dict['Naive Bayers'] = value330\n",
    "accuracy_dict['Naive Bayers'] = value340"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Linear Models: LogisticRegressionCV,  RidgeClassifierCV,  SGDClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of LogisticRegressionCV \n",
    "def LR_cv_model(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegressionCV(random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for LRcv model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for LRcv model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for LRcv model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for LRcv model is [[41  1]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.988095238095238\n",
      "\n",
      "The f1_score for LRcv model is 0.9914529914529915\n",
      "\n",
      "The performace of features selected_features on the LR_cv_model is 0.99\n",
      "\n",
      "The confusion matrix for LRcv model is [[40  2]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.9761904761904762\n",
      "\n",
      "The f1_score for LRcv model is 0.983050847457627\n",
      "\n",
      "The performace of features thr_gram_features on the LR_cv_model is 0.98\n",
      "\n",
      "The confusion matrix for LRcv model is [[40  2]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.9761904761904762\n",
      "\n",
      "The f1_score for LRcv model is 0.983050847457627\n",
      "\n",
      "The performace of features four_gram_features on the LR_cv_model is 0.98\n",
      "\n",
      "The confusion matrix for LRcv model is [[40  2]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.9761904761904762\n",
      "\n",
      "The f1_score for LRcv model is 0.983050847457627\n",
      "\n",
      "The performace of features tf_idf_all on the LR_cv_model is 0.98\n",
      "\n",
      "The confusion matrix for LRcv model is [[41  1]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.988095238095238\n",
      "\n",
      "The f1_score for LRcv model is 0.9914529914529915\n",
      "\n",
      "The performace of features tf_idf_part on the LR_cv_model is 0.99\n",
      "\n",
      "The confusion matrix for LRcv model is [[40  2]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.9761904761904762\n",
      "\n",
      "The f1_score for LRcv model is 0.983050847457627\n",
      "\n",
      "The performace of features united_features on the LR_cv_model is 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value410, value420, value430, value440 = [], [], [], []\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value41, value42, value43, value44 = LR_cv_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value410.append(value41)\n",
    "    value420.append(value42)\n",
    "    value430.append(value43)\n",
    "    value440.append(value44)\n",
    "    \n",
    "    print('The performace of features {} on the LR_cv_model is {}\\n'.format(key, value44))\n",
    "\n",
    "confusion_matrix_dict['LogisticRegressionCV'] = value410\n",
    "roc_auc_score_dict['LogisticRegressionCV'] = value420\n",
    "f1_score_dict['LogisticRegressionCV'] = value430\n",
    "accuracy_dict['LogisticRegressionCV'] = value440"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of RidgeClassifierCV\n",
    "def RC_cv_model(X_train, X_test, y_train, y_test):\n",
    "    clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for RidgeClassifierCV model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for RidgeClassifierCV model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for RidgeClassifierCV model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features selected_features on the RC_cv_model is 1.0\n",
      "\n",
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the RC_cv_model is 1.0\n",
      "\n",
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the RC_cv_model is 1.0\n",
      "\n",
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the RC_cv_model is 1.0\n",
      "\n",
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the RC_cv_model is 1.0\n",
      "\n",
      "The confusion matrix for RidgeClassifierCV model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 1.0\n",
      "\n",
      "The performace of features united_features on the RC_cv_model is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value510, value520, value530, value540 = [], [], [], []\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value51, value52, value53, value54 = RC_cv_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    value510.append(value51)\n",
    "    value520.append(value52)\n",
    "    value530.append(value53)\n",
    "    value540.append(value54)\n",
    "    \n",
    "    print('The performace of features {} on the RC_cv_model is {}\\n'.format(key, value54))\n",
    "\n",
    "confusion_matrix_dict['RidgeClassifierCV'] = value510\n",
    "roc_auc_score_dict['RidgeClassifierCV'] = value520\n",
    "f1_score_dict['RidgeClassifierCV'] = value530\n",
    "accuracy_dict['RidgeClassifierCV'] = value540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of SGDClassifier\n",
    "def SGD_model(X_train, X_test, y_train, y_test):\n",
    "    clf = SGDClassifier(random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for SGDClassifier model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for SGDClassifier model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for SGDClassifier model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features selected_features on the SGD_model is 1.0\n",
      "\n",
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the SGD_model is 1.0\n",
      "\n",
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the SGD_model is 1.0\n",
      "\n",
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the SGD_model is 1.0\n",
      "\n",
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the SGD_model is 1.0\n",
      "\n",
      "The confusion matrix for SGDClassifier model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 1.0\n",
      "\n",
      "The f1_score for SGDClassifier model is 1.0\n",
      "\n",
      "The performace of features united_features on the SGD_model is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value610, value620, value630, value640 = [], [], [], []\n",
    "\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value61, value62, value63, value64 = SGD_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value610.append(value61)\n",
    "    value620.append(value62)\n",
    "    value630.append(value63)\n",
    "    value640.append(value64)\n",
    "    \n",
    "    print('The performace of features {} on the SGD_model is {}\\n'.format(key, value64))\n",
    "\n",
    "confusion_matrix_dict['SGDClassifier'] = value610\n",
    "roc_auc_score_dict['SGDClassifier'] = value620\n",
    "f1_score_dict['SGDClassifier'] = value630\n",
    "accuracy_dict['SGDClassifier'] = value640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of MLP model\n",
    "def MLP_model(X_train, X_test, y_train, y_test):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, alpha=1e-4,\n",
    "                                              solver='sgd', verbose=0, tol=1e-4, random_state=seed,\n",
    "                                              learning_rate_init=.1).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for MLP model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for MLP model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for MLP model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features selected_features on the MLP_model is 1.0\n",
      "\n",
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features thr_gram_features on the MLP_model is 1.0\n",
      "\n",
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features four_gram_features on the MLP_model is 1.0\n",
      "\n",
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features tf_idf_all on the MLP_model is 1.0\n",
      "\n",
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features tf_idf_part on the MLP_model is 1.0\n",
      "\n",
      "The confusion matrix for MLP model is [[42  0]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 1.0\n",
      "\n",
      "The f1_score for MLP model is 1.0\n",
      "\n",
      "The performace of features united_features on the MLP_model is 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value710, value720, value730, value740 = [], [], [], []\n",
    "\n",
    "\n",
    "for key, value in dataset_dict.items():\n",
    "    X_train, X_test, y_train, y_test = data_split(value, label)\n",
    "    value71, value72, value73, value74 = MLP_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    value710.append(value71)\n",
    "    value720.append(value72)\n",
    "    value730.append(value73)\n",
    "    value740.append(value74)\n",
    "    \n",
    "    print('The performace of features {} on the MLP_model is {}\\n'.format(key, value74))\n",
    "\n",
    "confusion_matrix_dict['MLP'] = value710\n",
    "roc_auc_score_dict['MLP'] = value720\n",
    "f1_score_dict['MLP'] = value730\n",
    "accuracy_dict['MLP'] = value740"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create the data type dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>feature_selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thr_gram_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>four_gram_features</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tf_idf_all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf_idf_part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>united_features</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dataset\n",
       "0   feature_selection\n",
       "1   thr_gram_features\n",
       "2  four_gram_features\n",
       "3          tf_idf_all\n",
       "4         tf_idf_part\n",
       "5     united_features"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_datatype = pd.DataFrame(dataset_type)\n",
    "df_datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dataframe for different Metrics Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Confusion_Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_selection</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[41, 1], [0, 58]], [[41,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[41, 1], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thr_gram_features</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[40, 2], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_gram_features</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[40, 2], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_all</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[36, 6], [0, 58]], [[42,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[40, 2], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_part</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[41, 1], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united_features</th>\n",
       "      <td>[[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[40, 2], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "      <td>[[42, 0], [0, 58]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  SVM  \\\n",
       "data type                                                               \n",
       "feature_selection   [[[42, 0], [0, 58]], [[41, 1], [0, 58]], [[41,...   \n",
       "thr_gram_features   [[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...   \n",
       "four_gram_features  [[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...   \n",
       "tf_idf_all          [[[42, 0], [0, 58]], [[36, 6], [0, 58]], [[42,...   \n",
       "tf_idf_part         [[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...   \n",
       "united_features     [[[42, 0], [0, 58]], [[37, 5], [0, 58]], [[42,...   \n",
       "\n",
       "                        Decision Trees        Naive Bayers  \\\n",
       "data type                                                    \n",
       "feature_selection   [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "thr_gram_features   [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "four_gram_features  [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "tf_idf_all          [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "tf_idf_part         [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "united_features     [[42, 0], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "\n",
       "                   LogisticRegressionCV   RidgeClassifierCV  \\\n",
       "data type                                                     \n",
       "feature_selection    [[41, 1], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "thr_gram_features    [[40, 2], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "four_gram_features   [[40, 2], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "tf_idf_all           [[40, 2], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "tf_idf_part          [[41, 1], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "united_features      [[40, 2], [0, 58]]  [[42, 0], [0, 58]]   \n",
       "\n",
       "                         SGDClassifier                 MLP  \n",
       "data type                                                   \n",
       "feature_selection   [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  \n",
       "thr_gram_features   [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  \n",
       "four_gram_features  [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  \n",
       "tf_idf_all          [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  \n",
       "tf_idf_part         [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  \n",
       "united_features     [[42, 0], [0, 58]]  [[42, 0], [0, 58]]  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_matrix = pd.DataFrame(confusion_matrix_dict)\n",
    "df_confusion_matrix['data type'] = df_datatype['dataset']\n",
    "df_confusion_matrix.set_index('data type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Roc_Auc_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_selection</th>\n",
       "      <td>[1.0, 0.988095238095238, 0.988095238095238]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thr_gram_features</th>\n",
       "      <td>[1.0, 0.9404761904761905, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_gram_features</th>\n",
       "      <td>[1.0, 0.9404761904761905, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_all</th>\n",
       "      <td>[1.0, 0.9285714285714286, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_part</th>\n",
       "      <td>[1.0, 0.9404761904761905, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united_features</th>\n",
       "      <td>[1.0, 0.9404761904761905, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            SVM  \\\n",
       "data type                                                         \n",
       "feature_selection   [1.0, 0.988095238095238, 0.988095238095238]   \n",
       "thr_gram_features                [1.0, 0.9404761904761905, 1.0]   \n",
       "four_gram_features               [1.0, 0.9404761904761905, 1.0]   \n",
       "tf_idf_all                       [1.0, 0.9285714285714286, 1.0]   \n",
       "tf_idf_part                      [1.0, 0.9404761904761905, 1.0]   \n",
       "united_features                  [1.0, 0.9404761904761905, 1.0]   \n",
       "\n",
       "                    Decision Trees  Naive Bayers  LogisticRegressionCV  \\\n",
       "data type                                                                \n",
       "feature_selection              1.0           1.0              0.988095   \n",
       "thr_gram_features              1.0           1.0              0.976190   \n",
       "four_gram_features             1.0           1.0              0.976190   \n",
       "tf_idf_all                     1.0           1.0              0.976190   \n",
       "tf_idf_part                    1.0           1.0              0.988095   \n",
       "united_features                1.0           1.0              0.976190   \n",
       "\n",
       "                    RidgeClassifierCV  SGDClassifier  MLP  \n",
       "data type                                                  \n",
       "feature_selection                 1.0            1.0  1.0  \n",
       "thr_gram_features                 1.0            1.0  1.0  \n",
       "four_gram_features                1.0            1.0  1.0  \n",
       "tf_idf_all                        1.0            1.0  1.0  \n",
       "tf_idf_part                       1.0            1.0  1.0  \n",
       "united_features                   1.0            1.0  1.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_roc_auc_score = pd.DataFrame(roc_auc_score_dict)\n",
    "df_roc_auc_score['data type'] = df_datatype['dataset']\n",
    "df_roc_auc_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_selection</th>\n",
       "      <td>[1.0, 0.9914529914529915, 0.9914529914529915]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thr_gram_features</th>\n",
       "      <td>[1.0, 0.9586776859504132, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_gram_features</th>\n",
       "      <td>[1.0, 0.9586776859504132, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_all</th>\n",
       "      <td>[1.0, 0.9508196721311475, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_part</th>\n",
       "      <td>[1.0, 0.9586776859504132, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united_features</th>\n",
       "      <td>[1.0, 0.9586776859504132, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              SVM  \\\n",
       "data type                                                           \n",
       "feature_selection   [1.0, 0.9914529914529915, 0.9914529914529915]   \n",
       "thr_gram_features                  [1.0, 0.9586776859504132, 1.0]   \n",
       "four_gram_features                 [1.0, 0.9586776859504132, 1.0]   \n",
       "tf_idf_all                         [1.0, 0.9508196721311475, 1.0]   \n",
       "tf_idf_part                        [1.0, 0.9586776859504132, 1.0]   \n",
       "united_features                    [1.0, 0.9586776859504132, 1.0]   \n",
       "\n",
       "                    Decision Trees  Naive Bayers  LogisticRegressionCV  \\\n",
       "data type                                                                \n",
       "feature_selection              1.0           1.0              0.991453   \n",
       "thr_gram_features              1.0           1.0              0.983051   \n",
       "four_gram_features             1.0           1.0              0.983051   \n",
       "tf_idf_all                     1.0           1.0              0.983051   \n",
       "tf_idf_part                    1.0           1.0              0.991453   \n",
       "united_features                1.0           1.0              0.983051   \n",
       "\n",
       "                    RidgeClassifierCV  SGDClassifier  MLP  \n",
       "data type                                                  \n",
       "feature_selection                 1.0            1.0  1.0  \n",
       "thr_gram_features                 1.0            1.0  1.0  \n",
       "four_gram_features                1.0            1.0  1.0  \n",
       "tf_idf_all                        1.0            1.0  1.0  \n",
       "tf_idf_part                       1.0            1.0  1.0  \n",
       "united_features                   1.0            1.0  1.0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f1_score = pd.DataFrame(f1_score_dict)\n",
    "df_f1_score['data type'] = df_datatype['dataset']\n",
    "df_f1_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_selection</th>\n",
       "      <td>[1.0, 0.99, 0.99]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thr_gram_features</th>\n",
       "      <td>[1.0, 0.95, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four_gram_features</th>\n",
       "      <td>[1.0, 0.95, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_all</th>\n",
       "      <td>[1.0, 0.94, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_idf_part</th>\n",
       "      <td>[1.0, 0.95, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>united_features</th>\n",
       "      <td>[1.0, 0.95, 1.0]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  SVM  Decision Trees  Naive Bayers  \\\n",
       "data type                                                             \n",
       "feature_selection   [1.0, 0.99, 0.99]             1.0           1.0   \n",
       "thr_gram_features    [1.0, 0.95, 1.0]             1.0           1.0   \n",
       "four_gram_features   [1.0, 0.95, 1.0]             1.0           1.0   \n",
       "tf_idf_all           [1.0, 0.94, 1.0]             1.0           1.0   \n",
       "tf_idf_part          [1.0, 0.95, 1.0]             1.0           1.0   \n",
       "united_features      [1.0, 0.95, 1.0]             1.0           1.0   \n",
       "\n",
       "                    LogisticRegressionCV  RidgeClassifierCV  SGDClassifier  \\\n",
       "data type                                                                    \n",
       "feature_selection                   0.99                1.0            1.0   \n",
       "thr_gram_features                   0.98                1.0            1.0   \n",
       "four_gram_features                  0.98                1.0            1.0   \n",
       "tf_idf_all                          0.98                1.0            1.0   \n",
       "tf_idf_part                         0.99                1.0            1.0   \n",
       "united_features                     0.98                1.0            1.0   \n",
       "\n",
       "                    MLP  \n",
       "data type                \n",
       "feature_selection   1.0  \n",
       "thr_gram_features   1.0  \n",
       "four_gram_features  1.0  \n",
       "tf_idf_all          1.0  \n",
       "tf_idf_part         1.0  \n",
       "united_features     1.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy = pd.DataFrame(accuracy_dict)\n",
    "df_accuracy['data type'] = df_datatype['dataset']\n",
    "df_accuracy.set_index('data type')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitdbd76ed984a5488496eb976b9e8b3b8e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

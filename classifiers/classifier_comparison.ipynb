{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifierCV, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the evaluation libraries\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "# import the processing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the random seed\n",
    "global seed\n",
    "seed = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the dataset fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from Feature-Selector\n",
    "X = np.loadtxt('../dataset/matrix/X_fs.csv')\n",
    "Y = np.loadtxt('../dataset/matrix/Y_str.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dict to save evaluation results\n",
    "confusion_matrix_dict = {}\n",
    "roc_auc_score_dict = {}\n",
    "f1_score_dict = {}\n",
    "accuracy_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = {'dataset': ['fs']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the classifier model based on sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create svm model\n",
    "# The polynomial and RBF are especially useful when the data-points are not linearly separable.\n",
    "def SVC_model(X_train, X_test, y_train, y_test):\n",
    "    accuracy_svc = []\n",
    "    confusion_matrix_svc = []\n",
    "    roc_auc_score_svc = []\n",
    "    f1_score_svc = []\n",
    "    for kernel in ('linear', 'poly', 'rbf'):\n",
    "        clf = SVC(kernel = kernel)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        \n",
    "        confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "        f1_score_value = f1_score(y_test, y_pred)\n",
    "        \n",
    "        print('The confusion matrix for kernel {} is {}\\n'.format(kernel, confusion_matrix_value))\n",
    "        print('The roc_aux_score for kernel {} is {}\\n'.format(kernel,roc_auc_score_value))\n",
    "        print('The f1_score for kernel {} is {}\\n'.format(kernel, f1_score_value))\n",
    "        accuracy_svc.append(np.round(accuracy, 6))\n",
    "        confusion_matrix_svc.append(confusion_matrix_value)\n",
    "        roc_auc_score_svc.append(np.round(roc_auc_score_value,6))\n",
    "        f1_score_svc.append(np.round(f1_score_value,6))\n",
    "        \n",
    "    return confusion_matrix_svc, roc_auc_score_svc, f1_score_svc, accuracy_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for kernel linear is [[33  6]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel linear is 0.9230769230769231\n",
      "\n",
      "The f1_score for kernel linear is 0.9508196721311475\n",
      "\n",
      "The confusion matrix for kernel poly is [[31  8]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel poly is 0.8974358974358975\n",
      "\n",
      "The f1_score for kernel poly is 0.9354838709677419\n",
      "\n",
      "The confusion matrix for kernel rbf is [[32  7]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for kernel rbf is 0.9102564102564102\n",
      "\n",
      "The f1_score for kernel rbf is 0.9430894308943091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value11, value12, value13, value14  = SVC_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "# write the metrics to dict\n",
    "confusion_matrix_dict['SVM'] = value11\n",
    "roc_auc_score_dict['SVM'] = value12\n",
    "f1_score_dict['SVM'] = value13\n",
    "accuracy_dict['SVM'] = value14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of Decision Trees\n",
    "def decision_tree(X_train, X_test, y_train, y_test):\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for decision trees model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for decision trees model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for decision trees model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for decision trees model is [[33  6]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for decision trees model is 0.9230769230769231\n",
      "\n",
      "The f1_score for decision trees model is 0.9508196721311475\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value21, value22, value23, value24 = decision_tree(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    \n",
    "confusion_matrix_dict['Decision Trees'] = value21\n",
    "roc_auc_score_dict['Decision Trees'] = value22\n",
    "f1_score_dict['Decision Trees'] = value23\n",
    "accuracy_dict['Decision Trees'] = value24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of Naive Bayers \n",
    "def naive_bayers_model(X_train, X_test, y_train, y_test):\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for Naive Bayers model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for Naive Bayers model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for Naive Bayers model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for Naive Bayers model is [[34  5]\n",
      " [27 31]]\n",
      "\n",
      "The roc_aux_score for Naive Bayers model is 0.7031388152077807\n",
      "\n",
      "The f1_score for Naive Bayers model is 0.6595744680851064\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value31, value32, value33, value34 = naive_bayers_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "confusion_matrix_dict['Naive Bayers'] = value31\n",
    "roc_auc_score_dict['Naive Bayers'] = value32\n",
    "f1_score_dict['Naive Bayers'] = value33\n",
    "accuracy_dict['Naive Bayers'] = value34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of LogisticRegressionCV \n",
    "def LR_cv_model(X_train, X_test, y_train, y_test):\n",
    "    clf = LogisticRegressionCV(random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for LRcv model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for LRcv model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for LRcv model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for LRcv model is [[32  7]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for LRcv model is 0.9102564102564102\n",
      "\n",
      "The f1_score for LRcv model is 0.9430894308943091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value41, value42, value43, value44 = LR_cv_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "confusion_matrix_dict['LogisticRegressionCV'] = value41\n",
    "roc_auc_score_dict['LogisticRegressionCV'] = value42\n",
    "f1_score_dict['LogisticRegressionCV'] = value43\n",
    "accuracy_dict['LogisticRegressionCV'] = value44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of RidgeClassifierCV\n",
    "def RC_cv_model(X_train, X_test, y_train, y_test):\n",
    "    clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for RidgeClassifierCV model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for RidgeClassifierCV model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for RidgeClassifierCV model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for RidgeClassifierCV model is [[32  7]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for RidgeClassifierCV model is 0.9102564102564102\n",
      "\n",
      "The f1_score for RidgeClassifierCV model is 0.9430894308943091\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value51, value52, value53, value54 = RC_cv_model(X_train, X_test, y_train, y_test)\n",
    "\n",
    "confusion_matrix_dict['RidgeClassifierCV'] = value51\n",
    "roc_auc_score_dict['RidgeClassifierCV'] = value52\n",
    "f1_score_dict['RidgeClassifierCV'] = value53\n",
    "accuracy_dict['RidgeClassifierCV'] = value54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of SGDClassifier\n",
    "def SGD_model(X_train, X_test, y_train, y_test):\n",
    "    clf = SGDClassifier(random_state=seed).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for SGDClassifier model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for SGDClassifier model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for SGDClassifier model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for SGDClassifier model is [[35  4]\n",
      " [ 2 56]]\n",
      "\n",
      "The roc_aux_score for SGDClassifier model is 0.931476569407604\n",
      "\n",
      "The f1_score for SGDClassifier model is 0.9491525423728815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value61, value62, value63, value64 = SGD_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "confusion_matrix_dict['SGDClassifier'] = value61\n",
    "roc_auc_score_dict['SGDClassifier'] = value62\n",
    "f1_score_dict['SGDClassifier'] = value63\n",
    "accuracy_dict['SGDClassifier'] = value64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The realization of MLP model\n",
    "def MLP_model(X_train, X_test, y_train, y_test):\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, alpha=1e-4,\n",
    "                                              solver='sgd', verbose=0, tol=1e-4, random_state=seed,\n",
    "                                              learning_rate_init=.1).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    confusion_matrix_value = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    roc_auc_score_value = roc_auc_score(y_test, y_pred)\n",
    "    f1_score_value = f1_score(y_test, y_pred)\n",
    "    \n",
    "    print('The confusion matrix for MLP model is {}\\n'.format(confusion_matrix_value))\n",
    "    print('The roc_aux_score for MLP model is {}\\n'.format(roc_auc_score_value))\n",
    "    print('The f1_score for MLP model is {}\\n'.format(f1_score_value))\n",
    "    \n",
    "    return confusion_matrix_value, roc_auc_score_value, f1_score_value, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for MLP model is [[32  7]\n",
      " [ 0 58]]\n",
      "\n",
      "The roc_aux_score for MLP model is 0.9102564102564102\n",
      "\n",
      "The f1_score for MLP model is 0.9430894308943091\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ren\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create the list to save the different result from different dataset\n",
    "value71, value72, value73, value74 = MLP_model(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "confusion_matrix_dict['MLP'] = value71\n",
    "roc_auc_score_dict['MLP'] = value72\n",
    "f1_score_dict['MLP'] = value73\n",
    "accuracy_dict['MLP'] = value74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Dataframe for different Metrics Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': ['ts']}\n",
      "{'SVM': [array([[33,  6],\n",
      "       [ 0, 58]], dtype=int64), array([[31,  8],\n",
      "       [ 0, 58]], dtype=int64), array([[32,  7],\n",
      "       [ 0, 58]], dtype=int64)], 'Decision Trees': array([[33,  6],\n",
      "       [ 0, 58]], dtype=int64), 'Naive Bayers': array([[34,  5],\n",
      "       [27, 31]], dtype=int64), 'LogisticRegressionCV': array([[32,  7],\n",
      "       [ 0, 58]], dtype=int64), 'RidgeClassifierCV': array([[32,  7],\n",
      "       [ 0, 58]], dtype=int64), 'SGDClassifier': array([[35,  4],\n",
      "       [ 2, 56]], dtype=int64), 'MLP': array([[32,  7],\n",
      "       [ 0, 58]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "# build the total dict\n",
    "print(dataset_type) \n",
    "print(confusion_matrix_dict)\n",
    "for key, value in confusion_matrix_dict.items():\n",
    "    confusion_matrix_dict[key] = np.array(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>[[[33, 6], [0, 58]], [[31, 8], [0, 58]], [[32,...</td>\n",
       "      <td>[[33, 6], [0, 58]]</td>\n",
       "      <td>[[34, 5], [27, 31]]</td>\n",
       "      <td>[[32, 7], [0, 58]]</td>\n",
       "      <td>[[32, 7], [0, 58]]</td>\n",
       "      <td>[[35, 4], [2, 56]]</td>\n",
       "      <td>[[32, 7], [0, 58]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         SVM  \\\n",
       "data type                                                      \n",
       "ts         [[[33, 6], [0, 58]], [[31, 8], [0, 58]], [[32,...   \n",
       "\n",
       "               Decision Trees         Naive Bayers LogisticRegressionCV  \\\n",
       "data type                                                                 \n",
       "ts         [[33, 6], [0, 58]]  [[34, 5], [27, 31]]   [[32, 7], [0, 58]]   \n",
       "\n",
       "            RidgeClassifierCV       SGDClassifier                 MLP  \n",
       "data type                                                              \n",
       "ts         [[32, 7], [0, 58]]  [[35, 4], [2, 56]]  [[32, 7], [0, 58]]  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Confusion_Matrix\n",
    "df_confusion_matrix = pd.DataFrame([confusion_matrix_dict], index=[0])\n",
    "df_confusion_matrix['data type'] = dataset_type['dataset']\n",
    "df_confusion_matrix.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[[33,  6],\n",
       "               [ 0, 58]],\n",
       "\n",
       "              [[31,  8],\n",
       "               [ 0, 58]],\n",
       "\n",
       "              [[32,  7],\n",
       "               [ 0, 58]]], dtype=int64)], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_matrix['SVM'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>[0.923077, 0.897436, 0.910256]</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.703139</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.931477</td>\n",
       "      <td>0.910256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SVM  Decision Trees  Naive Bayers  \\\n",
       "data type                                                                 \n",
       "ts         [0.923077, 0.897436, 0.910256]        0.923077      0.703139   \n",
       "\n",
       "           LogisticRegressionCV  RidgeClassifierCV  SGDClassifier       MLP  \n",
       "data type                                                                    \n",
       "ts                     0.910256           0.910256       0.931477  0.910256  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Roc_Auc_Score\n",
    "df_roc_auc_score = pd.DataFrame([roc_auc_score_dict])\n",
    "df_roc_auc_score['data type'] = dataset_type['dataset']\n",
    "df_roc_auc_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>[0.95082, 0.935484, 0.943089]</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.943089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     SVM  Decision Trees  Naive Bayers  \\\n",
       "data type                                                                \n",
       "ts         [0.95082, 0.935484, 0.943089]         0.95082      0.659574   \n",
       "\n",
       "           LogisticRegressionCV  RidgeClassifierCV  SGDClassifier       MLP  \n",
       "data type                                                                    \n",
       "ts                     0.943089           0.943089       0.949153  0.943089  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. F1_Score\n",
    "df_f1_score = pd.DataFrame([f1_score_dict])\n",
    "df_f1_score['data type'] = dataset_type['dataset']\n",
    "df_f1_score.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ts</th>\n",
       "      <td>[0.938144, 0.917526, 0.927835]</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.927835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      SVM  Decision Trees  Naive Bayers  \\\n",
       "data type                                                                 \n",
       "ts         [0.938144, 0.917526, 0.927835]        0.938144      0.670103   \n",
       "\n",
       "           LogisticRegressionCV  RidgeClassifierCV  SGDClassifier       MLP  \n",
       "data type                                                                    \n",
       "ts                     0.927835           0.927835       0.938144  0.927835  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Accuracy\n",
    "df_accuracy = pd.DataFrame([accuracy_dict])\n",
    "df_accuracy['data type'] = dataset_type['dataset']\n",
    "df_accuracy.set_index('data type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all the matrix\n",
    "df = pd.DataFrame(columns=df_accuracy.columns.values)\n",
    "# df = df.append(df_confusion_matrix, ignore_index=True)\n",
    "df = df.append(df_roc_auc_score, ignore_index=True)\n",
    "df = df.append(df_f1_score, ignore_index=True)\n",
    "df = df.append(df_accuracy, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>Decision Trees</th>\n",
       "      <th>Naive Bayers</th>\n",
       "      <th>LogisticRegressionCV</th>\n",
       "      <th>RidgeClassifierCV</th>\n",
       "      <th>SGDClassifier</th>\n",
       "      <th>MLP</th>\n",
       "      <th>data type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.923077, 0.897436, 0.910256]</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.703139</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.931477</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.95082, 0.935484, 0.943089]</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.943089</td>\n",
       "      <td>ts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.938144, 0.917526, 0.927835]</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.670103</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>ts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              SVM  Decision Trees  Naive Bayers  \\\n",
       "0  [0.923077, 0.897436, 0.910256]        0.923077      0.703139   \n",
       "1   [0.95082, 0.935484, 0.943089]        0.950820      0.659574   \n",
       "2  [0.938144, 0.917526, 0.927835]        0.938144      0.670103   \n",
       "\n",
       "   LogisticRegressionCV  RidgeClassifierCV  SGDClassifier       MLP data type  \n",
       "0              0.910256           0.910256       0.931477  0.910256        ts  \n",
       "1              0.943089           0.943089       0.949153  0.943089        ts  \n",
       "2              0.927835           0.927835       0.938144  0.927835        ts  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index= list([ 'roc_auc_score', 'f1_score', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc_score    [0.923077, 0.897436, 0.910256]\n",
      "f1_score          [0.95082, 0.935484, 0.943089]\n",
      "accuracy         [0.938144, 0.917526, 0.927835]\n",
      "Name: SVM, dtype: object\n"
     ]
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(df['SVM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfi.export(df.drop('data type', axis=1), 'matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\open_source_projects\\Analysis_Ransome_with_GAN\\classifiers\\classifier_comparison.ipynb Cell 37'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/open_source_projects/Analysis_Ransome_with_GAN/classifiers/classifier_comparison.ipynb#ch0000058?line=0'>1</a>\u001b[0m dfi\u001b[39m.\u001b[39;49mexport(df[\u001b[39m'\u001b[39;49m\u001b[39mSVM\u001b[39;49m\u001b[39m'\u001b[39;49m],\u001b[39m'\u001b[39;49m\u001b[39mconf_matrix.png\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\dataframe_image\\_pandas_accessor.py:24\u001b[0m, in \u001b[0;36mexport\u001b[1;34m(obj, filename, fontsize, max_rows, max_cols, table_conversion, chrome_path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=21'>22</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexport\u001b[39m(obj, filename, fontsize\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m, max_rows\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, max_cols\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=22'>23</a>\u001b[0m                table_conversion\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mchrome\u001b[39m\u001b[39m'\u001b[39m, chrome_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=23'>24</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _export(obj, filename, fontsize, max_rows, max_cols, table_conversion, chrome_path)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\dataframe_image\\_pandas_accessor.py:52\u001b[0m, in \u001b[0;36m_export\u001b[1;34m(obj, filename, fontsize, max_rows, max_cols, table_conversion, chrome_path)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m max_rows \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=49'>50</a>\u001b[0m     max_rows \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=51'>52</a>\u001b[0m \u001b[39mif\u001b[39;00m df\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m] \u001b[39m>\u001b[39m MAX_COLS \u001b[39mand\u001b[39;00m max_cols \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=52'>53</a>\u001b[0m     error_msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mYour DataFrame has more than \u001b[39m\u001b[39m{\u001b[39;00mMAX_COLS\u001b[39m}\u001b[39;00m\u001b[39m columns and will produce a huge \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=53'>54</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mimage file, possibly causing your computer to crash. Override this error \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=54'>55</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39mby explicitly setting `max_cols`. Use -1 for all columns.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='file:///c%3A/Users/ren/AppData/Local/Programs/Python/Python38/lib/site-packages/dataframe_image/_pandas_accessor.py?line=55'>56</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_styler:\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fecd871876602184e2def9d040398806a20c493ba8c7291bbd5a5358628e6cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Maximum, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import adam_v2\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from Ensemble_Classifiers import Ensemble_Classifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "global seed\n",
    "\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalGAN():\n",
    "    def __init__(self, blackbox, X, Y, threshold):\n",
    "        self.apifeature_dims = 69\n",
    "        self.z_dims = 30\n",
    "        self.generator_layers = [self.apifeature_dims+self.z_dims, 32, 32, 64 , self.apifeature_dims]\n",
    "        # self.generator_layers = [self.apifeature_dims+self.z_dims, 64, 64, 128 , self.apifeature_dims]\n",
    "\n",
    "        self.substitute_detector_layers = [self.apifeature_dims, 64, 64, 1]\n",
    "        # self.substitute_detector_layers = [self.apifeature_dims, 128, 128, 1]\n",
    "        self.blackbox = blackbox       \n",
    "        optimizer = adam_v2.Adam(learning_rate=0.0002, beta_1=0.5)\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # Build and Train blackbox_detector\n",
    "        self.blackbox_detector = self.build_blackbox_detector()\n",
    "\n",
    "        # Build and compile the substitute_detector\n",
    "        self.substitute_detector = self.build_substitute_detector()\n",
    "        self.substitute_detector.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes malware and noise as input and generates adversarial malware examples\n",
    "        example = Input(shape=(self.apifeature_dims,))\n",
    "        noise = Input(shape=(self.z_dims,))\n",
    "        input = [example, noise]\n",
    "        malware_examples = self.generator(input)\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.substitute_detector(malware_examples)\n",
    "\n",
    "        # The combined model  (stacked generator and substitute_detector)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(input, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        # For the combined model we will only train the generator\n",
    "        self.substitute_detector.trainable = False\n",
    "    \n",
    "\n",
    "    def build_blackbox_detector(self):\n",
    "        if self.blackbox in ['SVM']:\n",
    "            blackbox_detector = SVC(kernel = 'linear')\n",
    "        \n",
    "        elif self.blackbox in ['GB']:\n",
    "            blackbox_detector = GradientBoostingClassifier(random_state=seed)\n",
    "        \n",
    "        elif self.blackbox in ['SGD']:\n",
    "            blackbox_detector = SGDClassifier(random_state=seed)  \n",
    "\n",
    "        elif self.blackbox in ['DT']:\n",
    "            blackbox_detector = DecisionTreeClassifier(random_state=seed)\n",
    "        \n",
    "        elif self.blackbox in ['Ensem']:\n",
    "            blackbox_detector = Ensemble_Classifier()\n",
    "\n",
    "        return blackbox_detector\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        example = Input(shape=(self.apifeature_dims,))\n",
    "        noise = Input(shape=(self.z_dims,))\n",
    "        x = Concatenate(axis=1)([example, noise])\n",
    "        for dim in self.generator_layers[1:]:\n",
    "            x = Dense(dim)(x)\n",
    "        x = Activation(activation='tanh')(x)\n",
    "        x = Maximum()([example, x])\n",
    "        generator = Model([example, noise], x, name='generator')\n",
    "        generator.summary()\n",
    "        return generator\n",
    "\n",
    "    def build_substitute_detector(self):\n",
    "\n",
    "        input = Input(shape=(self.substitute_detector_layers[0],))\n",
    "        x = input\n",
    "        for dim in self.substitute_detector_layers[1:]:\n",
    "            x = Dense(dim)(x)\n",
    "        x = Activation(activation='sigmoid')(x)\n",
    "        substitute_detector = Model(input, x, name='substitute_detector')\n",
    "        substitute_detector.summary()\n",
    "        return substitute_detector\n",
    "\n",
    "    def load_data(self):\n",
    "        x_ben, x_ran,y_ben, y_ran = self.X[:self.threshold], self.X[self.threshold:], self.Y[:self.threshold], self.Y[self.threshold:]\n",
    "\n",
    "        return (x_ran, y_ran), (x_ben, y_ben)\n",
    "    \n",
    "    \n",
    "    def train(self, epochs, batch_size=32):\n",
    "\n",
    "        # Load and Split the dataset\n",
    "        (xmal, ymal), (xben, yben) = self.load_data()\n",
    "        xtrain_mal, xtest_mal, ytrain_mal, ytest_mal = train_test_split(xmal, ymal, test_size=0.50)\n",
    "        xtrain_ben, xtest_ben, ytrain_ben, ytest_ben = train_test_split(xben, yben, test_size=0.50)\n",
    "\n",
    "        bl_xtrain_mal, bl_ytrain_mal, bl_xtrain_ben, bl_ytrain_ben = xtrain_mal, ytrain_mal, xtrain_ben, ytrain_ben\n",
    "\n",
    "        \n",
    "        self.blackbox_detector.fit(np.concatenate([xmal, xben]), np.concatenate([ymal, yben]))\n",
    "\n",
    "        ytrain_ben_blackbox = self.blackbox_detector.predict(bl_xtrain_ben)\n",
    "        \n",
    "        Original_Train_TPR = self.blackbox_detector.score(bl_xtrain_mal, bl_ytrain_mal)\n",
    "        \n",
    "        Original_Test_TPR = self.blackbox_detector.score(xtest_mal, ytest_mal)\n",
    "        Train_TPR, Test_TPR = [Original_Train_TPR], [Original_Test_TPR]\n",
    "\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for step in range(xtrain_mal.shape[0] // batch_size):\n",
    "                # ---------------------\n",
    "                #  Train substitute_detector\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a random batch of malware examples\n",
    "                idx_mal = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n",
    "  \n",
    "                xmal_batch = xtrain_mal[idx_mal]\n",
    "                \n",
    "                noise = np.random.normal(0, 1, (batch_size, self.z_dims))\n",
    "                \n",
    "                idx_ben = np.random.randint(0, xmal_batch.shape[0], batch_size)\n",
    "                \n",
    "                xben_batch = xtrain_ben[idx_ben]\n",
    "                yben_batch = ytrain_ben_blackbox[idx_ben]\n",
    "\n",
    "                # Generate a batch of new malware examples\n",
    "                gen_examples = self.generator.predict([xmal_batch, noise])\n",
    "                ymal_batch = self.blackbox_detector.predict(np.ones(gen_examples.shape)*(gen_examples > 0.5))\n",
    "\n",
    "                # Train the substitute_detector\n",
    "\n",
    "                d_loss_real = self.substitute_detector.train_on_batch(gen_examples, ymal_batch)\n",
    "                d_loss_fake = self.substitute_detector.train_on_batch(xben_batch, yben_batch)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                idx = np.random.randint(0, xtrain_mal.shape[0], batch_size)\n",
    "                xmal_batch = xtrain_mal[idx]\n",
    "                noise = np.random.uniform(0, 1, (batch_size, self.z_dims))\n",
    "\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([xmal_batch, noise], np.zeros((batch_size, 1)))\n",
    "\n",
    "            # Compute Train TPR\n",
    "            noise = np.random.uniform(0, 1, (xtrain_mal.shape[0], self.z_dims))\n",
    "            gen_examples = self.generator.predict([xtrain_mal, noise])\n",
    "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytrain_mal)\n",
    "            Train_TPR.append(TPR)\n",
    "\n",
    "            # Compute Test TPR\n",
    "            noise = np.random.uniform(0, 1, (xtest_mal.shape[0], self.z_dims))\n",
    "            gen_examples = self.generator.predict([xtest_mal, noise])\n",
    "            TPR = self.blackbox_detector.score(np.ones(gen_examples.shape) * (gen_examples > 0.5), ytest_mal)\n",
    "            Test_TPR.append(TPR)\n",
    "\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "            if int(epoch) == int(epochs-1):\n",
    "                return  d_loss[0], 100*d_loss[1], g_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dict to save the D loss, acc and G loss for different classifiers\n",
    "D_loss_dict, Acc_dict, G_loss_dict = {}, {}, {}\n",
    "# get the data from Feature-Selector\n",
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('../dataset/matrix/CLaMP.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      66\n",
       "float64     3\n",
       "object      1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['e_cblp', 'e_cp', 'e_cparhdr', 'e_maxalloc', 'e_sp', 'e_lfanew',\n",
       "       'NumberOfSections', 'CreationYear', 'FH_char0', 'FH_char1', 'FH_char2',\n",
       "       'FH_char3', 'FH_char4', 'FH_char5', 'FH_char6', 'FH_char7', 'FH_char8',\n",
       "       'FH_char9', 'FH_char10', 'FH_char11', 'FH_char12', 'FH_char13',\n",
       "       'FH_char14', 'MajorLinkerVersion', 'MinorLinkerVersion', 'SizeOfCode',\n",
       "       'SizeOfInitializedData', 'SizeOfUninitializedData',\n",
       "       'AddressOfEntryPoint', 'BaseOfCode', 'BaseOfData', 'ImageBase',\n",
       "       'SectionAlignment', 'FileAlignment', 'MajorOperatingSystemVersion',\n",
       "       'MinorOperatingSystemVersion', 'MajorImageVersion', 'MinorImageVersion',\n",
       "       'MajorSubsystemVersion', 'MinorSubsystemVersion', 'SizeOfImage',\n",
       "       'SizeOfHeaders', 'CheckSum', 'Subsystem', 'OH_DLLchar0', 'OH_DLLchar1',\n",
       "       'OH_DLLchar2', 'OH_DLLchar3', 'OH_DLLchar4', 'OH_DLLchar5',\n",
       "       'OH_DLLchar6', 'OH_DLLchar7', 'OH_DLLchar8', 'OH_DLLchar9',\n",
       "       'OH_DLLchar10', 'SizeOfStackReserve', 'SizeOfStackCommit',\n",
       "       'SizeOfHeapReserve', 'SizeOfHeapCommit', 'LoaderFlags', 'sus_sections',\n",
       "       'non_sus_sections', 'packer', 'packer_type', 'E_text', 'E_data',\n",
       "       'filesize', 'E_file', 'fileinfo', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "df['packer_type'] = LabelEncoder().fit_transform(df['packer_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18    4395\n",
       "32     231\n",
       "4      154\n",
       "5      110\n",
       "16      93\n",
       "17      90\n",
       "7       25\n",
       "31      14\n",
       "15      13\n",
       "27       9\n",
       "10       9\n",
       "24       8\n",
       "20       8\n",
       "28       7\n",
       "25       5\n",
       "29       4\n",
       "3        4\n",
       "0        3\n",
       "36       2\n",
       "33       2\n",
       "39       2\n",
       "30       2\n",
       "6        2\n",
       "11       2\n",
       "35       1\n",
       "23       1\n",
       "8        1\n",
       "12       1\n",
       "19       1\n",
       "38       1\n",
       "34       1\n",
       "26       1\n",
       "2        1\n",
       "1        1\n",
       "22       1\n",
       "9        1\n",
       "13       1\n",
       "14       1\n",
       "21       1\n",
       "37       1\n",
       "Name: packer_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['packer_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['class'].values\n",
    "X = df.drop('class', axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5210, 69)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        7.12092577e-03, 8.05612826e-01, 1.00000000e+00],\n",
       "       [3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        3.70775942e-05, 6.20165013e-01, 0.00000000e+00],\n",
       "       [3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        3.39974503e-04, 7.88645721e-01, 1.00000000e+00],\n",
       "       ...,\n",
       "       [3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        1.36260159e-03, 9.74947062e-01, 0.00000000e+00],\n",
       "       [3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        1.62986925e-03, 9.83855633e-01, 0.00000000e+00],\n",
       "       [3.89105058e-03, 1.49625935e-04, 3.11259824e-04, ...,\n",
       "        7.78629479e-04, 9.07294642e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X = MinMaxScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\open_source_projects\\Analysis_Ransome_with_GAN\\models\\GAN_Mal.ipynb Cell 11'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/open_source_projects/Analysis_Ransome_with_GAN/models/GAN_Mal.ipynb#ch0000015?line=0'>1</a>\u001b[0m X\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2488, 1: 2722})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] \n",
      "Training the model with SVM classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_26 (InputLayer)       [(None, 69)]              0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 64)                4480      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 69)]         0           []                               \n",
      "                                                                                                  \n",
      " input_28 (InputLayer)          [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 99)           0           ['input_27[0][0]',               \n",
      "                                                                  'input_28[0][0]']               \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 32)           3200        ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 32)           1056        ['dense_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 64)           2112        ['dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 69)           4485        ['dense_40[0][0]']               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 69)           0           ['dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " maximum_5 (Maximum)            (None, 69)           0           ['input_27[0][0]',               \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,853\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.539537, acc.: 71.88%] [G loss: 0.045343]\n",
      "1 [D loss: 0.514337, acc.: 73.44%] [G loss: 0.012183]\n",
      "2 [D loss: 0.479212, acc.: 79.69%] [G loss: 0.008032]\n",
      "3 [D loss: 0.321460, acc.: 92.19%] [G loss: 0.003344]\n",
      "4 [D loss: 0.327451, acc.: 92.19%] [G loss: 0.002011]\n",
      "5 [D loss: 0.294928, acc.: 90.62%] [G loss: 0.000550]\n",
      "6 [D loss: 0.215045, acc.: 95.31%] [G loss: 0.000192]\n",
      "7 [D loss: 0.189461, acc.: 93.75%] [G loss: 0.000056]\n",
      "8 [D loss: 0.161751, acc.: 96.88%] [G loss: 0.000027]\n",
      "9 [D loss: 0.183761, acc.: 95.31%] [G loss: 0.000020]\n",
      "10 [D loss: 0.250592, acc.: 92.19%] [G loss: 0.000012]\n",
      "11 [D loss: 0.142484, acc.: 96.88%] [G loss: 0.000011]\n",
      "12 [D loss: 0.253131, acc.: 92.19%] [G loss: 0.000012]\n",
      "13 [D loss: 0.179309, acc.: 95.31%] [G loss: 0.000002]\n",
      "14 [D loss: 0.124512, acc.: 96.88%] [G loss: 0.000019]\n",
      "15 [D loss: 0.298732, acc.: 87.50%] [G loss: 0.000006]\n",
      "16 [D loss: 0.381269, acc.: 85.94%] [G loss: 0.000002]\n",
      "17 [D loss: 0.178112, acc.: 93.75%] [G loss: 0.000013]\n",
      "18 [D loss: 0.213450, acc.: 89.06%] [G loss: 0.000007]\n",
      "19 [D loss: 0.196237, acc.: 95.31%] [G loss: 0.000002]\n",
      "20 [D loss: 0.255417, acc.: 92.19%] [G loss: 0.000001]\n",
      "21 [D loss: 0.096326, acc.: 96.88%] [G loss: 0.000001]\n",
      "22 [D loss: 0.175630, acc.: 93.75%] [G loss: 0.000005]\n",
      "23 [D loss: 0.118437, acc.: 93.75%] [G loss: 0.000000]\n",
      "24 [D loss: 0.056320, acc.: 100.00%] [G loss: 0.000000]\n",
      "25 [D loss: 0.148634, acc.: 95.31%] [G loss: 0.000001]\n",
      "26 [D loss: 0.168127, acc.: 95.31%] [G loss: 0.000000]\n",
      "27 [D loss: 0.106564, acc.: 96.88%] [G loss: 0.000000]\n",
      "28 [D loss: 0.082563, acc.: 96.88%] [G loss: 0.000000]\n",
      "29 [D loss: 0.196098, acc.: 95.31%] [G loss: 0.000000]\n",
      "30 [D loss: 0.204871, acc.: 92.19%] [G loss: 0.000001]\n",
      "31 [D loss: 0.178122, acc.: 95.31%] [G loss: 0.000000]\n",
      "32 [D loss: 0.085559, acc.: 98.44%] [G loss: 0.000000]\n",
      "33 [D loss: 0.107219, acc.: 98.44%] [G loss: 0.000000]\n",
      "34 [D loss: 0.270811, acc.: 90.62%] [G loss: 0.000001]\n",
      "35 [D loss: 0.070889, acc.: 100.00%] [G loss: 0.000002]\n",
      "36 [D loss: 0.151385, acc.: 95.31%] [G loss: 0.000000]\n",
      "37 [D loss: 0.103830, acc.: 96.88%] [G loss: 0.000001]\n",
      "38 [D loss: 0.122855, acc.: 96.88%] [G loss: 0.000001]\n",
      "39 [D loss: 0.104025, acc.: 95.31%] [G loss: 0.000001]\n",
      "40 [D loss: 0.045923, acc.: 100.00%] [G loss: 0.000000]\n",
      "41 [D loss: 0.054304, acc.: 100.00%] [G loss: 0.000001]\n",
      "42 [D loss: 0.267024, acc.: 92.19%] [G loss: 0.000000]\n",
      "43 [D loss: 0.145469, acc.: 96.88%] [G loss: 0.000000]\n",
      "44 [D loss: 0.234447, acc.: 95.31%] [G loss: 0.000001]\n",
      "45 [D loss: 0.121235, acc.: 95.31%] [G loss: 0.000000]\n",
      "46 [D loss: 0.098315, acc.: 95.31%] [G loss: 0.000000]\n",
      "47 [D loss: 0.156507, acc.: 95.31%] [G loss: 0.000000]\n",
      "48 [D loss: 0.118286, acc.: 96.88%] [G loss: 0.000000]\n",
      "49 [D loss: 0.214374, acc.: 92.19%] [G loss: 0.000000]\n",
      "[+] \n",
      "Training the model with SGD classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_31 (InputLayer)       [(None, 69)]              0         \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 64)                4480      \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_32 (InputLayer)          [(None, 69)]         0           []                               \n",
      "                                                                                                  \n",
      " input_33 (InputLayer)          [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 99)           0           ['input_32[0][0]',               \n",
      "                                                                  'input_33[0][0]']               \n",
      "                                                                                                  \n",
      " dense_45 (Dense)               (None, 32)           3200        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " dense_46 (Dense)               (None, 32)           1056        ['dense_45[0][0]']               \n",
      "                                                                                                  \n",
      " dense_47 (Dense)               (None, 64)           2112        ['dense_46[0][0]']               \n",
      "                                                                                                  \n",
      " dense_48 (Dense)               (None, 69)           4485        ['dense_47[0][0]']               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 69)           0           ['dense_48[0][0]']               \n",
      "                                                                                                  \n",
      " maximum_6 (Maximum)            (None, 69)           0           ['input_32[0][0]',               \n",
      "                                                                  'activation_13[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,853\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.560470, acc.: 79.69%] [G loss: 0.070669]\n",
      "1 [D loss: 0.631458, acc.: 76.56%] [G loss: 0.063685]\n",
      "2 [D loss: 0.526189, acc.: 78.12%] [G loss: 0.026516]\n",
      "3 [D loss: 0.434511, acc.: 76.56%] [G loss: 0.016415]\n",
      "4 [D loss: 0.375236, acc.: 84.38%] [G loss: 0.012311]\n",
      "5 [D loss: 0.426508, acc.: 76.56%] [G loss: 0.008566]\n",
      "6 [D loss: 0.382926, acc.: 82.81%] [G loss: 0.011727]\n",
      "7 [D loss: 0.302153, acc.: 81.25%] [G loss: 0.006293]\n",
      "8 [D loss: 0.267416, acc.: 87.50%] [G loss: 0.000785]\n",
      "9 [D loss: 0.281879, acc.: 84.38%] [G loss: 0.000301]\n",
      "10 [D loss: 0.210437, acc.: 92.19%] [G loss: 0.000570]\n",
      "11 [D loss: 0.230503, acc.: 92.19%] [G loss: 0.000295]\n",
      "12 [D loss: 0.224950, acc.: 90.62%] [G loss: 0.000174]\n",
      "13 [D loss: 0.241756, acc.: 90.62%] [G loss: 0.000258]\n",
      "14 [D loss: 0.132709, acc.: 96.88%] [G loss: 0.000145]\n",
      "15 [D loss: 0.189781, acc.: 95.31%] [G loss: 0.000062]\n",
      "16 [D loss: 0.130304, acc.: 96.88%] [G loss: 0.000039]\n",
      "17 [D loss: 0.233896, acc.: 90.62%] [G loss: 0.000340]\n",
      "18 [D loss: 0.187010, acc.: 95.31%] [G loss: 0.000132]\n",
      "19 [D loss: 0.220850, acc.: 92.19%] [G loss: 0.000070]\n",
      "20 [D loss: 0.255564, acc.: 87.50%] [G loss: 0.000020]\n",
      "21 [D loss: 0.272240, acc.: 90.62%] [G loss: 0.000057]\n",
      "22 [D loss: 0.170161, acc.: 93.75%] [G loss: 0.000018]\n",
      "23 [D loss: 0.156027, acc.: 95.31%] [G loss: 0.000056]\n",
      "24 [D loss: 0.183404, acc.: 93.75%] [G loss: 0.000006]\n",
      "25 [D loss: 0.176130, acc.: 95.31%] [G loss: 0.000039]\n",
      "26 [D loss: 0.128596, acc.: 95.31%] [G loss: 0.000022]\n",
      "27 [D loss: 0.253872, acc.: 90.62%] [G loss: 0.000012]\n",
      "28 [D loss: 0.174997, acc.: 92.19%] [G loss: 0.000007]\n",
      "29 [D loss: 0.097610, acc.: 98.44%] [G loss: 0.000027]\n",
      "30 [D loss: 0.131244, acc.: 95.31%] [G loss: 0.000004]\n",
      "31 [D loss: 0.137328, acc.: 96.88%] [G loss: 0.000013]\n",
      "32 [D loss: 0.144717, acc.: 90.62%] [G loss: 0.000003]\n",
      "33 [D loss: 0.298392, acc.: 90.62%] [G loss: 0.000032]\n",
      "34 [D loss: 0.163233, acc.: 96.88%] [G loss: 0.000002]\n",
      "35 [D loss: 0.079941, acc.: 96.88%] [G loss: 0.000004]\n",
      "36 [D loss: 0.078496, acc.: 98.44%] [G loss: 0.000001]\n",
      "37 [D loss: 0.121086, acc.: 93.75%] [G loss: 0.000000]\n",
      "38 [D loss: 0.103405, acc.: 95.31%] [G loss: 0.000001]\n",
      "39 [D loss: 0.084932, acc.: 96.88%] [G loss: 0.000001]\n",
      "40 [D loss: 0.127238, acc.: 95.31%] [G loss: 0.000005]\n",
      "41 [D loss: 0.100307, acc.: 96.88%] [G loss: 0.000003]\n",
      "42 [D loss: 0.137738, acc.: 95.31%] [G loss: 0.000002]\n",
      "43 [D loss: 0.151586, acc.: 90.62%] [G loss: 0.000001]\n",
      "44 [D loss: 0.135681, acc.: 93.75%] [G loss: 0.000001]\n",
      "45 [D loss: 0.063676, acc.: 98.44%] [G loss: 0.000002]\n",
      "46 [D loss: 0.213562, acc.: 93.75%] [G loss: 0.000001]\n",
      "47 [D loss: 0.208648, acc.: 95.31%] [G loss: 0.000001]\n",
      "48 [D loss: 0.137129, acc.: 93.75%] [G loss: 0.000000]\n",
      "49 [D loss: 0.136670, acc.: 95.31%] [G loss: 0.000000]\n",
      "[+] \n",
      "Training the model with DT classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_36 (InputLayer)       [(None, 69)]              0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 64)                4480      \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_37 (InputLayer)          [(None, 69)]         0           []                               \n",
      "                                                                                                  \n",
      " input_38 (InputLayer)          [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 99)           0           ['input_37[0][0]',               \n",
      "                                                                  'input_38[0][0]']               \n",
      "                                                                                                  \n",
      " dense_52 (Dense)               (None, 32)           3200        ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_53 (Dense)               (None, 32)           1056        ['dense_52[0][0]']               \n",
      "                                                                                                  \n",
      " dense_54 (Dense)               (None, 64)           2112        ['dense_53[0][0]']               \n",
      "                                                                                                  \n",
      " dense_55 (Dense)               (None, 69)           4485        ['dense_54[0][0]']               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 69)           0           ['dense_55[0][0]']               \n",
      "                                                                                                  \n",
      " maximum_7 (Maximum)            (None, 69)           0           ['input_37[0][0]',               \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,853\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.470500, acc.: 76.56%] [G loss: 0.015478]\n",
      "1 [D loss: 0.281149, acc.: 92.19%] [G loss: 0.007004]\n",
      "2 [D loss: 0.249665, acc.: 90.62%] [G loss: 0.003139]\n",
      "3 [D loss: 0.274744, acc.: 90.62%] [G loss: 0.002155]\n",
      "4 [D loss: 0.277593, acc.: 84.38%] [G loss: 0.001984]\n",
      "5 [D loss: 0.268764, acc.: 85.94%] [G loss: 0.001235]\n",
      "6 [D loss: 0.264095, acc.: 85.94%] [G loss: 0.000876]\n",
      "7 [D loss: 0.234939, acc.: 90.62%] [G loss: 0.001125]\n",
      "8 [D loss: 0.259193, acc.: 90.62%] [G loss: 0.001170]\n",
      "9 [D loss: 0.195469, acc.: 95.31%] [G loss: 0.001250]\n",
      "10 [D loss: 0.177671, acc.: 90.62%] [G loss: 0.000567]\n",
      "11 [D loss: 0.119328, acc.: 93.75%] [G loss: 0.002052]\n",
      "12 [D loss: 0.203810, acc.: 93.75%] [G loss: 0.000603]\n",
      "13 [D loss: 0.196677, acc.: 89.06%] [G loss: 0.001937]\n",
      "14 [D loss: 0.250313, acc.: 89.06%] [G loss: 0.000496]\n",
      "15 [D loss: 0.307570, acc.: 89.06%] [G loss: 0.001236]\n",
      "16 [D loss: 0.148317, acc.: 92.19%] [G loss: 0.000761]\n",
      "17 [D loss: 0.183912, acc.: 93.75%] [G loss: 0.001219]\n",
      "18 [D loss: 0.395257, acc.: 82.81%] [G loss: 0.000799]\n",
      "19 [D loss: 0.209102, acc.: 90.62%] [G loss: 0.000840]\n",
      "20 [D loss: 0.309130, acc.: 87.50%] [G loss: 0.001170]\n",
      "21 [D loss: 0.137122, acc.: 92.19%] [G loss: 0.000931]\n",
      "22 [D loss: 0.206550, acc.: 92.19%] [G loss: 0.000514]\n",
      "23 [D loss: 0.144322, acc.: 96.88%] [G loss: 0.000513]\n",
      "24 [D loss: 0.248394, acc.: 90.62%] [G loss: 0.001212]\n",
      "25 [D loss: 0.215556, acc.: 90.62%] [G loss: 0.000886]\n",
      "26 [D loss: 0.195571, acc.: 90.62%] [G loss: 0.000503]\n",
      "27 [D loss: 0.274772, acc.: 82.81%] [G loss: 0.000395]\n",
      "28 [D loss: 0.384415, acc.: 87.50%] [G loss: 0.000267]\n",
      "29 [D loss: 0.165094, acc.: 95.31%] [G loss: 0.000276]\n",
      "30 [D loss: 0.195638, acc.: 89.06%] [G loss: 0.000270]\n",
      "31 [D loss: 0.293304, acc.: 90.62%] [G loss: 0.000317]\n",
      "32 [D loss: 0.314830, acc.: 87.50%] [G loss: 0.000181]\n",
      "33 [D loss: 0.132081, acc.: 96.88%] [G loss: 0.000239]\n",
      "34 [D loss: 0.202171, acc.: 95.31%] [G loss: 0.000273]\n",
      "35 [D loss: 0.228417, acc.: 89.06%] [G loss: 0.000298]\n",
      "36 [D loss: 0.219766, acc.: 89.06%] [G loss: 0.000439]\n",
      "37 [D loss: 0.166166, acc.: 93.75%] [G loss: 0.000247]\n",
      "38 [D loss: 0.164932, acc.: 92.19%] [G loss: 0.000438]\n",
      "39 [D loss: 0.209162, acc.: 92.19%] [G loss: 0.000281]\n",
      "40 [D loss: 0.218597, acc.: 87.50%] [G loss: 0.000259]\n",
      "41 [D loss: 0.300279, acc.: 87.50%] [G loss: 0.000495]\n",
      "42 [D loss: 0.216715, acc.: 89.06%] [G loss: 0.000433]\n",
      "43 [D loss: 0.237669, acc.: 90.62%] [G loss: 0.000547]\n",
      "44 [D loss: 0.190998, acc.: 93.75%] [G loss: 0.000509]\n",
      "45 [D loss: 0.276852, acc.: 90.62%] [G loss: 0.000604]\n",
      "46 [D loss: 0.213999, acc.: 92.19%] [G loss: 0.000429]\n",
      "47 [D loss: 0.167948, acc.: 90.62%] [G loss: 0.000252]\n",
      "48 [D loss: 0.218098, acc.: 90.62%] [G loss: 0.000273]\n",
      "49 [D loss: 0.182178, acc.: 92.19%] [G loss: 0.000247]\n",
      "[+] \n",
      "Training the model with GB classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_41 (InputLayer)       [(None, 69)]              0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 64)                4480      \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_42 (InputLayer)          [(None, 69)]         0           []                               \n",
      "                                                                                                  \n",
      " input_43 (InputLayer)          [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 99)           0           ['input_42[0][0]',               \n",
      "                                                                  'input_43[0][0]']               \n",
      "                                                                                                  \n",
      " dense_59 (Dense)               (None, 32)           3200        ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dense_60 (Dense)               (None, 32)           1056        ['dense_59[0][0]']               \n",
      "                                                                                                  \n",
      " dense_61 (Dense)               (None, 64)           2112        ['dense_60[0][0]']               \n",
      "                                                                                                  \n",
      " dense_62 (Dense)               (None, 69)           4485        ['dense_61[0][0]']               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 69)           0           ['dense_62[0][0]']               \n",
      "                                                                                                  \n",
      " maximum_8 (Maximum)            (None, 69)           0           ['input_42[0][0]',               \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,853\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.573416, acc.: 71.88%] [G loss: 0.042877]\n",
      "1 [D loss: 0.313247, acc.: 90.62%] [G loss: 0.014194]\n",
      "2 [D loss: 0.265982, acc.: 90.62%] [G loss: 0.009463]\n",
      "3 [D loss: 0.392246, acc.: 81.25%] [G loss: 0.010947]\n",
      "4 [D loss: 0.259212, acc.: 87.50%] [G loss: 0.011197]\n",
      "5 [D loss: 0.248394, acc.: 89.06%] [G loss: 0.005363]\n",
      "6 [D loss: 0.250565, acc.: 89.06%] [G loss: 0.004234]\n",
      "7 [D loss: 0.222129, acc.: 90.62%] [G loss: 0.004072]\n",
      "8 [D loss: 0.223532, acc.: 89.06%] [G loss: 0.001930]\n",
      "9 [D loss: 0.300477, acc.: 85.94%] [G loss: 0.001843]\n",
      "10 [D loss: 0.146298, acc.: 93.75%] [G loss: 0.001027]\n",
      "11 [D loss: 0.284012, acc.: 87.50%] [G loss: 0.001909]\n",
      "12 [D loss: 0.184279, acc.: 90.62%] [G loss: 0.000594]\n",
      "13 [D loss: 0.106002, acc.: 95.31%] [G loss: 0.000729]\n",
      "14 [D loss: 0.122617, acc.: 96.88%] [G loss: 0.000205]\n",
      "15 [D loss: 0.145742, acc.: 89.06%] [G loss: 0.000101]\n",
      "16 [D loss: 0.215438, acc.: 90.62%] [G loss: 0.000074]\n",
      "17 [D loss: 0.243511, acc.: 89.06%] [G loss: 0.000081]\n",
      "18 [D loss: 0.151225, acc.: 90.62%] [G loss: 0.000060]\n",
      "19 [D loss: 0.219926, acc.: 93.75%] [G loss: 0.000134]\n",
      "20 [D loss: 0.203309, acc.: 90.62%] [G loss: 0.000166]\n",
      "21 [D loss: 0.158108, acc.: 92.19%] [G loss: 0.000054]\n",
      "22 [D loss: 0.174401, acc.: 93.75%] [G loss: 0.000076]\n",
      "23 [D loss: 0.179505, acc.: 92.19%] [G loss: 0.000153]\n",
      "24 [D loss: 0.172350, acc.: 93.75%] [G loss: 0.000060]\n",
      "25 [D loss: 0.202041, acc.: 93.75%] [G loss: 0.000059]\n",
      "26 [D loss: 0.311082, acc.: 89.06%] [G loss: 0.000049]\n",
      "27 [D loss: 0.173305, acc.: 90.62%] [G loss: 0.000071]\n",
      "28 [D loss: 0.146377, acc.: 92.19%] [G loss: 0.000034]\n",
      "29 [D loss: 0.109577, acc.: 96.88%] [G loss: 0.000011]\n",
      "30 [D loss: 0.176321, acc.: 92.19%] [G loss: 0.000047]\n",
      "31 [D loss: 0.106688, acc.: 96.88%] [G loss: 0.000028]\n",
      "32 [D loss: 0.204070, acc.: 90.62%] [G loss: 0.000030]\n",
      "33 [D loss: 0.276153, acc.: 87.50%] [G loss: 0.000033]\n",
      "34 [D loss: 0.130390, acc.: 95.31%] [G loss: 0.000022]\n",
      "35 [D loss: 0.107560, acc.: 93.75%] [G loss: 0.000018]\n",
      "36 [D loss: 0.244759, acc.: 92.19%] [G loss: 0.000029]\n",
      "37 [D loss: 0.207966, acc.: 89.06%] [G loss: 0.000065]\n",
      "38 [D loss: 0.129487, acc.: 92.19%] [G loss: 0.000009]\n",
      "39 [D loss: 0.128798, acc.: 93.75%] [G loss: 0.000041]\n",
      "40 [D loss: 0.200801, acc.: 89.06%] [G loss: 0.000046]\n",
      "41 [D loss: 0.112566, acc.: 93.75%] [G loss: 0.000020]\n",
      "42 [D loss: 0.192431, acc.: 87.50%] [G loss: 0.000037]\n",
      "43 [D loss: 0.102662, acc.: 96.88%] [G loss: 0.000028]\n",
      "44 [D loss: 0.072342, acc.: 95.31%] [G loss: 0.000033]\n",
      "45 [D loss: 0.140514, acc.: 96.88%] [G loss: 0.000014]\n",
      "46 [D loss: 0.182096, acc.: 92.19%] [G loss: 0.000027]\n",
      "47 [D loss: 0.126825, acc.: 95.31%] [G loss: 0.000007]\n",
      "48 [D loss: 0.172399, acc.: 90.62%] [G loss: 0.000026]\n",
      "49 [D loss: 0.085044, acc.: 98.44%] [G loss: 0.000014]\n",
      "[+] \n",
      "Training the model with Ensem classifier\n",
      "\n",
      "Model: \"substitute_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_46 (InputLayer)       [(None, 69)]              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 64)                4480      \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,705\n",
      "Trainable params: 8,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"generator\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_47 (InputLayer)          [(None, 69)]         0           []                               \n",
      "                                                                                                  \n",
      " input_48 (InputLayer)          [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 99)           0           ['input_47[0][0]',               \n",
      "                                                                  'input_48[0][0]']               \n",
      "                                                                                                  \n",
      " dense_66 (Dense)               (None, 32)           3200        ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dense_67 (Dense)               (None, 32)           1056        ['dense_66[0][0]']               \n",
      "                                                                                                  \n",
      " dense_68 (Dense)               (None, 64)           2112        ['dense_67[0][0]']               \n",
      "                                                                                                  \n",
      " dense_69 (Dense)               (None, 69)           4485        ['dense_68[0][0]']               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 69)           0           ['dense_69[0][0]']               \n",
      "                                                                                                  \n",
      " maximum_9 (Maximum)            (None, 69)           0           ['input_47[0][0]',               \n",
      "                                                                  'activation_19[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,853\n",
      "Trainable params: 10,853\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "0 [D loss: 0.725446, acc.: 64.06%] [G loss: 0.106034]\n",
      "1 [D loss: 0.472506, acc.: 82.81%] [G loss: 0.044921]\n",
      "2 [D loss: 0.493638, acc.: 78.12%] [G loss: 0.046864]\n",
      "3 [D loss: 0.429565, acc.: 81.25%] [G loss: 0.024836]\n",
      "4 [D loss: 0.472476, acc.: 79.69%] [G loss: 0.011504]\n",
      "5 [D loss: 0.355399, acc.: 82.81%] [G loss: 0.006065]\n",
      "6 [D loss: 0.352146, acc.: 89.06%] [G loss: 0.005009]\n",
      "7 [D loss: 0.261766, acc.: 87.50%] [G loss: 0.005003]\n",
      "8 [D loss: 0.435049, acc.: 81.25%] [G loss: 0.003219]\n",
      "9 [D loss: 0.323544, acc.: 87.50%] [G loss: 0.002419]\n",
      "10 [D loss: 0.309001, acc.: 85.94%] [G loss: 0.002507]\n",
      "11 [D loss: 0.217984, acc.: 90.62%] [G loss: 0.002454]\n",
      "12 [D loss: 0.318078, acc.: 89.06%] [G loss: 0.002410]\n",
      "13 [D loss: 0.295441, acc.: 85.94%] [G loss: 0.001993]\n",
      "14 [D loss: 0.294457, acc.: 92.19%] [G loss: 0.001727]\n",
      "15 [D loss: 0.305529, acc.: 87.50%] [G loss: 0.001971]\n",
      "16 [D loss: 0.293821, acc.: 90.62%] [G loss: 0.001392]\n",
      "17 [D loss: 0.263283, acc.: 92.19%] [G loss: 0.001976]\n",
      "18 [D loss: 0.332522, acc.: 87.50%] [G loss: 0.001959]\n",
      "19 [D loss: 0.396115, acc.: 82.81%] [G loss: 0.000624]\n",
      "20 [D loss: 0.432034, acc.: 81.25%] [G loss: 0.001168]\n",
      "21 [D loss: 0.357209, acc.: 84.38%] [G loss: 0.001341]\n",
      "22 [D loss: 0.266621, acc.: 87.50%] [G loss: 0.001281]\n",
      "23 [D loss: 0.277092, acc.: 89.06%] [G loss: 0.000914]\n",
      "24 [D loss: 0.200488, acc.: 95.31%] [G loss: 0.000854]\n",
      "25 [D loss: 0.319952, acc.: 87.50%] [G loss: 0.000716]\n",
      "26 [D loss: 0.314751, acc.: 87.50%] [G loss: 0.000990]\n",
      "27 [D loss: 0.355572, acc.: 85.94%] [G loss: 0.001957]\n",
      "28 [D loss: 0.273745, acc.: 89.06%] [G loss: 0.000668]\n",
      "29 [D loss: 0.184017, acc.: 92.19%] [G loss: 0.000616]\n",
      "30 [D loss: 0.247044, acc.: 89.06%] [G loss: 0.000610]\n",
      "31 [D loss: 0.436773, acc.: 79.69%] [G loss: 0.000571]\n",
      "32 [D loss: 0.354982, acc.: 84.38%] [G loss: 0.001340]\n",
      "33 [D loss: 0.240508, acc.: 90.62%] [G loss: 0.001228]\n",
      "34 [D loss: 0.235917, acc.: 92.19%] [G loss: 0.000923]\n",
      "35 [D loss: 0.287815, acc.: 87.50%] [G loss: 0.000744]\n",
      "36 [D loss: 0.320785, acc.: 87.50%] [G loss: 0.001186]\n",
      "37 [D loss: 0.263758, acc.: 87.50%] [G loss: 0.001270]\n",
      "38 [D loss: 0.356739, acc.: 85.94%] [G loss: 0.001088]\n",
      "39 [D loss: 0.353877, acc.: 82.81%] [G loss: 0.001489]\n",
      "40 [D loss: 0.248005, acc.: 90.62%] [G loss: 0.000971]\n",
      "41 [D loss: 0.206246, acc.: 90.62%] [G loss: 0.000793]\n",
      "42 [D loss: 0.189100, acc.: 93.75%] [G loss: 0.000844]\n",
      "43 [D loss: 0.330642, acc.: 90.62%] [G loss: 0.000715]\n",
      "44 [D loss: 0.334137, acc.: 85.94%] [G loss: 0.000845]\n",
      "45 [D loss: 0.271033, acc.: 85.94%] [G loss: 0.002023]\n",
      "46 [D loss: 0.249067, acc.: 89.06%] [G loss: 0.001103]\n",
      "47 [D loss: 0.311791, acc.: 84.38%] [G loss: 0.000498]\n",
      "48 [D loss: 0.384985, acc.: 84.38%] [G loss: 0.000987]\n",
      "49 [D loss: 0.319834, acc.: 89.06%] [G loss: 0.001135]\n",
      "=====================\n",
      "{'SVM': 0.2143743298947811, 'SGD': 0.1366698555648327, 'DT': 0.18217830266803503, 'GB': 0.08504400122910738, 'Ensem': 0.31983402371406555}\n",
      "=====================\n",
      "{'SVM': 92.1875, 'SGD': 95.3125, 'DT': 92.1875, 'GB': 98.4375, 'Ensem': 89.0625}\n",
      "=====================\n",
      "{'SVM': 3.931344494390032e-08, 'SGD': 2.905404699049541e-07, 'DT': 0.00024743395624682307, 'GB': 1.3990780644235201e-05, 'Ensem': 0.0011351570719853044}\n"
     ]
    }
   ],
   "source": [
    "# load the classifier\n",
    "for classifier in [ 'SVM', 'SGD', 'DT', 'GB', 'Ensem']: \n",
    "    print('[+] \\nTraining the model with {} classifier\\n'.format(classifier))\n",
    "    malgan = MalGAN(blackbox=classifier, X=X, Y=Y, threshold = 2488)\n",
    "    d_loss, acc, g_loss = malgan.train(epochs=50, batch_size=32)\n",
    "\n",
    "    D_loss_dict[classifier] = d_loss\n",
    "    Acc_dict[classifier] = acc \n",
    "    G_loss_dict[classifier] = g_loss\n",
    "\n",
    "\n",
    "print('=====================')\n",
    "print(D_loss_dict)\n",
    "print('=====================')\n",
    "print(Acc_dict)\n",
    "print('=====================')\n",
    "print(G_loss_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_dict = {}\n",
    "\n",
    "for key, value in D_loss_dict.items():\n",
    "    matrix_dict[key] = []\n",
    "\n",
    "\n",
    "for key, value in D_loss_dict.items():\n",
    "    matrix_dict[key].append(D_loss_dict[key])\n",
    "    matrix_dict[key].append(Acc_dict[key])\n",
    "    matrix_dict[key].append(G_loss_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SGD</th>\n",
       "      <th>DT</th>\n",
       "      <th>GB</th>\n",
       "      <th>Ensem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>D_Loss</th>\n",
       "      <td>2.143743e-01</td>\n",
       "      <td>1.366699e-01</td>\n",
       "      <td>0.182178</td>\n",
       "      <td>0.085044</td>\n",
       "      <td>0.319834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc</th>\n",
       "      <td>9.218750e+01</td>\n",
       "      <td>9.531250e+01</td>\n",
       "      <td>92.187500</td>\n",
       "      <td>98.437500</td>\n",
       "      <td>89.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G_Loss</th>\n",
       "      <td>3.931344e-08</td>\n",
       "      <td>2.905405e-07</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.001135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SVM           SGD         DT         GB      Ensem\n",
       "D_Loss  2.143743e-01  1.366699e-01   0.182178   0.085044   0.319834\n",
       "Acc     9.218750e+01  9.531250e+01  92.187500  98.437500  89.062500\n",
       "G_Loss  3.931344e-08  2.905405e-07   0.000247   0.000014   0.001135"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(matrix_dict, orient='columns') \n",
    "df.index= list([ 'D_Loss', 'Acc', 'G_Loss'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(df, '64_mal_matrix.png')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fecd871876602184e2def9d040398806a20c493ba8c7291bbd5a5358628e6cd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
